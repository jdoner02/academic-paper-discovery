{
  "download_info": {
    "timestamp": "2025-08-07T15:59:45.992085+00:00",
    "strategy_name": "AI-Powered Threat Detection and Security Analytics",
    "total_papers": 20,
    "download_directory": "outputs/artificial_intelligence_security/ai_powered_threat_detection/pdfs"
  },
  "papers": [
    {
      "title": "Towards Explainable and Lightweight AI for Real-Time Cyber Threat   Hunting in Edge Networks",
      "authors": [
        "Milad Rahmati"
      ],
      "abstract": "As cyber threats continue to evolve, securing edge networks has become increasingly challenging due to their distributed nature and resource limitations. Many AI-driven threat detection systems rely on complex deep learning models, which, despite their high accuracy, suffer from two major drawbacks: lack of interpretability and high computational cost. Black-box AI models make it difficult for security analysts to understand the reasoning behind their predictions, limiting their practical deployment. Moreover, conventional deep learning techniques demand significant computational resources, rendering them unsuitable for edge devices with limited processing power. To address these issues, this study introduces an Explainable and Lightweight AI (ELAI) framework designed for real-time cyber threat detection in edge networks. Our approach integrates interpretable machine learning algorithms with optimized lightweight deep learning techniques, ensuring both transparency and computational efficiency. The proposed system leverages decision trees, attention-based deep learning, and federated learning to enhance detection accuracy while maintaining explainability. We evaluate ELAI using benchmark cybersecurity datasets, such as CICIDS and UNSW-NB15, assessing its performance across diverse cyberattack scenarios. Experimental results demonstrate that the proposed framework achieves high detection rates with minimal false positives, all while significantly reducing computational demands compared to traditional deep learning methods. The key contributions of this work include: (1) a novel interpretable AI-based cybersecurity model tailored for edge computing environments, (2) an optimized lightweight deep learning approach for real-time cyber threat detection, and (3) a comprehensive analysis of explainability techniques in AI-driven cybersecurity applications.",
      "publication_date": "2025-04-18T23:45:39+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "2504.16118v1"
    },
    {
      "title": "CyberSentinel: An Emergent Threat Detection System for AI Security",
      "authors": [
        "Krti Tallam"
      ],
      "abstract": "The rapid advancement of artificial intelligence (AI) has significantly expanded the attack surface for AI-driven cybersecurity threats, necessitating adaptive defense strategies. This paper introduces CyberSentinel, a unified, single-agent system for emergent threat detection, designed to identify and mitigate novel security risks in real time. CyberSentinel integrates: (1) Brute-force attack detection through SSH log analysis, (2) Phishing threat assessment using domain blacklists and heuristic URL scoring, and (3) Emergent threat detection via machine learning-based anomaly detection. By continuously adapting to evolving adversarial tactics, CyberSentinel strengthens proactive cybersecurity defense, addressing critical vulnerabilities in AI security.",
      "publication_date": "2025-02-20T19:03:32+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "2502.14966v1"
    },
    {
      "title": "Autonomous Threat Hunting: A Future Paradigm for AI-Driven Threat   Intelligence",
      "authors": [
        "Siva Raja Sindiramutty"
      ],
      "abstract": "The evolution of cybersecurity has spurred the emergence of autonomous threat hunting as a pivotal paradigm in the realm of AI-driven threat intelligence. This review navigates through the intricate landscape of autonomous threat hunting, exploring its significance and pivotal role in fortifying cyber defense mechanisms. Delving into the amalgamation of artificial intelligence (AI) and traditional threat intelligence methodologies, this paper delineates the necessity and evolution of autonomous approaches in combating contemporary cyber threats. Through a comprehensive exploration of foundational AI-driven threat intelligence, the review accentuates the transformative influence of AI and machine learning on conventional threat intelligence practices. It elucidates the conceptual framework underpinning autonomous threat hunting, spotlighting its components, and the seamless integration of AI algorithms within threat hunting processes.. Insightful discussions on challenges encompassing scalability, interpretability, and ethical considerations in AI-driven models enrich the discourse. Moreover, through illuminating case studies and evaluations, this paper showcases real-world implementations, underscoring success stories and lessons learned by organizations adopting AI-driven threat intelligence. In conclusion, this review consolidates key insights, emphasizing the substantial implications of autonomous threat hunting for the future of cybersecurity. It underscores the significance of continual research and collaborative efforts in harnessing the potential of AI-driven approaches to fortify cyber defenses against evolving threats.",
      "publication_date": "2023-12-30T17:36:08+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "2401.00286v1"
    },
    {
      "title": "Generating Cyber Threat Intelligence to Discover Potential Security   Threats Using Classification and Topic Modeling",
      "authors": [
        "Md Imran Hossen",
        "Ashraful Islam",
        "Farzana Anowar",
        "Eshtiak Ahmed",
        "Mohammad Masudur Rahman",
        "Xiali",
        "Hei"
      ],
      "abstract": "Due to the variety of cyber-attacks or threats, the cybersecurity community enhances the traditional security control mechanisms to an advanced level so that automated tools can encounter potential security threats. Very recently, Cyber Threat Intelligence (CTI) has been presented as one of the proactive and robust mechanisms because of its automated cybersecurity threat prediction. Generally, CTI collects and analyses data from various sources e.g., online security forums, social media where cyber enthusiasts, analysts, even cybercriminals discuss cyber or computer security-related topics and discovers potential threats based on the analysis. As the manual analysis of every such discussion (posts on online platforms) is time-consuming, inefficient, and susceptible to errors, CTI as an automated tool can perform uniquely to detect cyber threats. In this paper, we identify and explore relevant CTI from hacker forums utilizing different supervised (classification) and unsupervised learning (topic modeling) techniques. To this end, we collect data from a real hacker forum and constructed two datasets: a binary dataset and a multi-class dataset. We then apply several classifiers along with deep neural network-based classifiers and use them on the datasets to compare their performances. We also employ the classifiers on a labeled leaked dataset as our ground truth. We further explore the datasets using unsupervised techniques. For this purpose, we leverage two topic modeling algorithms namely Latent Dirichlet Allocation (LDA) and Non-negative Matrix Factorization (NMF).",
      "publication_date": "2021-08-16T02:30:29+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.LG"
      ],
      "arxiv_id": "2108.06862v3"
    },
    {
      "title": "Trustworthy Artificial Intelligence for Cyber Threat Analysis",
      "authors": [
        "Shuangbao Paul Wang",
        "Paul Mullin"
      ],
      "abstract": "Artificial Intelligence brings innovations into the society. However, bias and unethical exist in many algorithms that make the applications less trustworthy. Threats hunting algorithms based on machine learning have shown great advantage over classical methods. Reinforcement learning models are getting more accurate for identifying not only signature-based but also behavior-based threats. Quantum mechanics brings a new dimension in improving classification speed with exponential advantage. In this research, we developed a machine learning based cyber threat detection and assessment tool. It uses two stage, unsupervised and supervised learning, analyzing method on log data recorded from a web server on AWS cloud. The results show the algorithm has the ability to identify cyber threats with high confidence.",
      "publication_date": "2025-06-18T15:44:31+00:00",
      "doi": "10.1007/978-3-031-16072-1_36",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "2506.19052v1"
    },
    {
      "title": "A Threat Intelligence Event Extraction Conceptual Model for Cyber Threat   Intelligence Feeds",
      "authors": [
        "Jamal H. Al-Yasiri",
        "Mohamad Fadli Bin Zolkipli",
        "Nik Fatinah N Mohd Farid",
        "Mohammed Alsamman",
        "Zainab Ali Mohammed"
      ],
      "abstract": "In response to the escalating cyber threats, the efficiency of Cyber Threat Intelligence (CTI) data collection has become paramount in ensuring robust cybersecurity. However, existing works encounter significant challenges in preprocessing large volumes of multilingual threat data, leading to inefficiencies in real-time threat analysis. This paper presents a systematic review of current techniques aimed at enhancing CTI data collection efficiency. Additionally, it proposes a conceptual model to further advance the effectiveness of threat intelligence feeds. Following the PRISMA guidelines, the review examines relevant studies from the Scopus database, highlighting the critical role of artificial intelligence (AI) and machine learning models in optimizing CTI data preprocessing. The findings underscore the importance of AI-driven methods, particularly supervised and unsupervised learning, in significantly improving the accuracy of threat detection and event extraction, thereby strengthening cybersecurity. Furthermore, the study identifies a gap in the existing research and introduces XBC conceptual model integrating XLM-RoBERTa, BiGRU, and CRF, specifically developed to address this gap. This paper contributes conceptually to the field by providing a detailed analysis of current CTI data collection techniques and introducing an innovative conceptual model to enhance future threat intelligence capabilities.",
      "publication_date": "2025-06-04T04:09:01+00:00",
      "doi": "10.1109/NETAPPS63333.2024.10823639",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "2506.03551v1"
    },
    {
      "title": "Using a Collated Cybersecurity Dataset for Machine Learning and   Artificial Intelligence",
      "authors": [
        "Erik Hemberg",
        "Una-May O'Reilly"
      ],
      "abstract": "Artificial Intelligence (AI) and Machine Learning (ML) algorithms can support the span of indicator-level, e.g. anomaly detection, to behavioral level cyber security modeling and inference. This contribution is based on a dataset named BRON which is amalgamated from public threat and vulnerability behavioral sources. We demonstrate how BRON can support prediction of related threat techniques and attack patterns. We also discuss other AI and ML uses of BRON to exploit its behavioral knowledge.",
      "publication_date": "2021-08-05T13:52:31+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "2108.02618v1"
    },
    {
      "title": "A Deep Learning Perspective on Connected Automated Vehicle (CAV)   Cybersecurity and Threat Intelligence",
      "authors": [
        "Manoj Basnet",
        "Mohd. Hasan Ali"
      ],
      "abstract": "The automation and connectivity of CAV inherit most of the cyber-physical vulnerabilities of incumbent technologies such as evolving network architectures, wireless communications, and AI-based automation. This book chapter entails the cyber-physical vulnerabilities and risks that originated in IT, OT, and the physical domains of the CAV ecosystem, eclectic threat landscapes, and threat intelligence. To deal with the security threats in high-speed, high dimensional, multimodal data and assets from eccentric stakeholders of the CAV ecosystem, this chapter presents and analyzes some of the state of art deep learning-based threat intelligence for attack detection. The frontiers in deep learning, namely Meta-Learning and Federated Learning, along with their challenges have been included in the chapter. We have proposed, trained, and tested the deep CNN-LSTM architecture for CAV threat intelligence; assessed and compared the performance of the proposed model against other deep learning algorithms such as DNN, CNN, LSTM. Our results indicate the superiority of the proposed model although DNN and 1d-CNN also achieved more than 99% of accuracy, precision, recall, f1-score, and AUC on the CAV-KDD dataset. The good performance of deep CNN-LSTM comes with the increased model complexity and cumbersome hyperparameters tuning. Still, there are open challenges on deep learning adoption in the CAV cybersecurity paradigm due to lack of properly developed protocols and policies, poorly defined privileges between stakeholders, costlier training, adversarial threats to the model, and poor generalizability of the model under out of data distributions.",
      "publication_date": "2021-09-22T14:41:01+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "2109.10763v1"
    },
    {
      "title": "AI-Driven Security in Cloud Computing: Enhancing Threat Detection,   Automated Response, and Cyber Resilience",
      "authors": [
        "Shamnad Mohamed Shaffi",
        "Sunish Vengathattil",
        "Jezeena Nikarthil Sidhick",
        "Resmi Vijayan"
      ],
      "abstract": "Cloud security concerns have been greatly realized in recent years due to the increase of complicated threats in the computing world. Many traditional solutions do not work well in real-time to detect or prevent more complex threats. Artificial intelligence is today regarded as a revolution in determining a protection plan for cloud data architecture through machine learning, statistical visualization of computing infrastructure, and detection of security breaches followed by counteraction. These AI-enabled systems make work easier as more network activities are scrutinized, and any anomalous behavior that might be a precursor to a more serious breach is prevented. This paper examines ways AI can enhance cloud security by applying predictive analytics, behavior-based security threat detection, and AI-stirring encryption. It also outlines the problems of the previous security models and how AI overcomes them. For a similar reason, issues like data privacy, biases in the AI model, and regulatory compliance are also covered. So, AI improves the protection of cloud computing contexts; however, more efforts are needed in the subsequent phases to extend the technology's reliability, modularity, and ethical aspects. This means that AI can be blended with other new computing technologies, including blockchain, to improve security frameworks further. The paper discusses the current trends in securing cloud data architecture using AI and presents further research and application directions.",
      "publication_date": "2025-05-06T19:45:13+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "2505.03945v1"
    },
    {
      "title": "AI assisted Malware Analysis: A Course for Next Generation Cybersecurity   Workforce",
      "authors": [
        "Maanak Gupta",
        "Sudip Mittal",
        "Mahmoud Abdelsalam"
      ],
      "abstract": "The use of Artificial Intelligence (AI) and Machine Learning (ML) to solve cybersecurity problems has been gaining traction within industry and academia, in part as a response to widespread malware attacks on critical systems, such as cloud infrastructures, government offices or hospitals, and the vast amounts of data they generate. AI- and ML-assisted cybersecurity offers data-driven automation that could enable security systems to identify and respond to cyber threats in real time. However, there is currently a shortfall of professionals trained in AI and ML for cybersecurity. Here we address the shortfall by developing lab-intensive modules that enable undergraduate and graduate students to gain fundamental and advanced knowledge in applying AI and ML techniques to real-world datasets to learn about Cyber Threat Intelligence (CTI), malware analysis, and classification, among other important topics in cybersecurity.   Here we describe six self-contained and adaptive modules in \"AI-assisted Malware Analysis.\" Topics include: (1) CTI and malware attack stages, (2) malware knowledge representation and CTI sharing, (3) malware data collection and feature identification, (4) AI-assisted malware detection, (5) malware classification and attribution, and (6) advanced malware research topics and case studies such as adversarial learning and Advanced Persistent Threat (APT) detection.",
      "publication_date": "2020-09-21T22:03:02+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "2009.11101v1"
    },
    {
      "title": "Gathering Cyber Threat Intelligence from Twitter Using Novelty   Classification",
      "authors": [
        "Ba Dung Le",
        "Guanhua Wang",
        "Mehwish Nasim",
        "Ali Babar"
      ],
      "abstract": "Preventing organizations from Cyber exploits needs timely intelligence about Cyber vulnerabilities and attacks, referred as threats. Cyber threat intelligence can be extracted from various sources including social media platforms where users publish the threat information in real time. Gathering Cyber threat intelligence from social media sites is a time consuming task for security analysts that can delay timely response to emerging Cyber threats. We propose a framework for automatically gathering Cyber threat intelligence from Twitter by using a novelty detection model. Our model learns the features of Cyber threat intelligence from the threat descriptions published in public repositories such as Common Vulnerabilities and Exposures (CVE) and classifies a new unseen tweet as either normal or anomalous to Cyber threat intelligence. We evaluate our framework using a purpose-built data set of tweets from 50 influential Cyber security related accounts over twelve months (in 2018). Our classifier achieves the F1-score of 0.643 for classifying Cyber threat tweets and outperforms several baselines including binary classification models. Our analysis of the classification results suggests that Cyber threat relevant tweets on Twitter do not often include the CVE identifier of the related threats. Hence, it would be valuable to collect these tweets and associate them with the related CVE identifier for cyber security applications.",
      "publication_date": "2019-07-03T06:31:52+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "1907.01755v2"
    },
    {
      "title": "CTI4AI: Threat Intelligence Generation and Sharing after Red Teaming AI   Models",
      "authors": [
        "Chuyen Nguyen",
        "Caleb Morgan",
        "Sudip Mittal"
      ],
      "abstract": "As the practicality of Artificial Intelligence (AI) and Machine Learning (ML) based techniques grow, there is an ever increasing threat of adversarial attacks. There is a need to red team this ecosystem to identify system vulnerabilities, potential threats, characterize properties that will enhance system robustness, and encourage the creation of effective defenses. A secondary need is to share this AI security threat intelligence between different stakeholders like, model developers, users, and AI/ML security professionals. In this paper, we create and describe a prototype system CTI4AI, to overcome the need to methodically identify and share AI/ML specific vulnerabilities and threat intelligence.",
      "publication_date": "2022-08-16T00:16:58+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "2208.07476v1"
    },
    {
      "title": "Cybersecurity Threat Hunting and Vulnerability Analysis Using a Neo4j   Graph Database of Open Source Intelligence",
      "authors": [
        "Elijah Pelofske",
        "Lorie M. Liebrock",
        "Vincent Urias"
      ],
      "abstract": "Open source intelligence is a powerful tool for cybersecurity analysts to gather information both for analysis of discovered vulnerabilities and for detecting novel cybersecurity threats and exploits. However the scale of information that is relevant for information security on the internet is always increasing, and is intractable for analysts to parse comprehensively. Therefore methods of condensing the available open source intelligence, and automatically developing connections between disparate sources of information, is incredibly valuable. In this research, we present a system which constructs a Neo4j graph database formed by shared connections between open source intelligence text including blogs, cybersecurity bulletins, news sites, antivirus scans, social media posts (e.g., Reddit and Twitter), and threat reports. These connections are comprised of possible indicators of compromise (e.g., IP addresses, domains, hashes, email addresses, phone numbers), information on known exploits and techniques (e.g., CVEs and MITRE ATT&CK Technique ID's), and potential sources of information on cybersecurity exploits such as twitter usernames. The construction of the database of potential IoCs is detailed, including the addition of machine learning and metadata which can be used for filtering of the data for a specific domain (for example a specific natural language) when needed. Examples of utilizing the graph database for querying connections between known malicious IoCs and open source intelligence documents, including threat reports, are shown. We show three specific examples of interesting connections found in the graph database; the connections to a known exploited CVE, a known malicious IP address, and a malware hash signature.",
      "publication_date": "2023-01-27T22:29:22+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "2301.12013v2"
    },
    {
      "title": "Unraveling Threat Intelligence Through the Lens of Malicious URL   Campaigns",
      "authors": [
        "Mahathir Almashor",
        "Ejaz Ahmed",
        "Benjamin Pick",
        "Sharif Abuadbba",
        "Jason Xue",
        "Raj Gaire",
        "Shuo Wang",
        "Seyit Camtepe",
        "Surya Nepal"
      ],
      "abstract": "The daily deluge of alerts is a sombre reality for Security Operations Centre (SOC) personnel worldwide. They are at the forefront of an organisation's cybersecurity infrastructure, and face the unenviable task of prioritising threats amongst a flood of abstruse alerts triggered by their Security Information and Event Management (SIEM) systems. URLs found within malicious communications form the bulk of such alerts, and pinpointing pertinent patterns within them allows teams to rapidly deescalate potential or extant threats. This need for vigilance has been traditionally filled with machine-learning based log analysis tools and anomaly detection concepts. To sidestep machine learning approaches, we instead propose to analyse suspicious URLs from SIEM alerts via the perspective of malicious URL campaigns. By first grouping URLs within 311M records gathered from VirusTotal into 2.6M suspicious clusters, we thereafter discovered 77.8K malicious campaigns. Corroborating our suspicions, we found 9.9M unique URLs attributable to 18.3K multi-URL campaigns, and that worryingly, only 2.97% of campaigns were found by security vendors. We also confer insights on evasive tactics such as ever lengthier URLs and more diverse domain names, with selected case studies exposing other adversarial techniques. By characterising the concerted campaigns driving these URL alerts, we hope to inform SOC teams of current threat trends, and thus arm them with better threat intelligence.",
      "publication_date": "2022-08-26T06:10:13+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "2208.12449v1"
    },
    {
      "title": "Exploring Feature Importance and Explainability Towards Enhanced   ML-Based DoS Detection in AI Systems",
      "authors": [
        "Paul Badu Yakubu",
        "Evans Owusu",
        "Lesther Santana",
        "Mohamed Rahouti",
        "Abdellah Chehri",
        "Kaiqi Xiong"
      ],
      "abstract": "Denial of Service (DoS) attacks pose a significant threat in the realm of AI systems security, causing substantial financial losses and downtime. However, AI systems' high computational demands, dynamic behavior, and data variability make monitoring and detecting DoS attacks challenging. Nowadays, statistical and machine learning (ML)-based DoS classification and detection approaches utilize a broad range of feature selection mechanisms to select a feature subset from networking traffic datasets. Feature selection is critical in enhancing the overall model performance and attack detection accuracy while reducing the training time. In this paper, we investigate the importance of feature selection in improving ML-based detection of DoS attacks. Specifically, we explore feature contribution to the overall components in DoS traffic datasets by utilizing statistical analysis and feature engineering approaches. Our experimental findings demonstrate the usefulness of the thorough statistical analysis of DoS traffic and feature engineering in understanding the behavior of the attack and identifying the best feature selection for ML-based DoS classification and detection.",
      "publication_date": "2024-11-04T19:51:08+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "2411.03355v1"
    },
    {
      "title": "AI-Driven Cybersecurity Threat Detection: Building Resilient Defense   Systems Using Predictive Analytics",
      "authors": [
        "Biswajit Chandra Das",
        "M Saif Sartaz",
        "Syed Ali Reza",
        "Arat Hossain",
        "Md Nasiruddin",
        "Kanchon Kumar Bishnu",
        "Kazi Sharmin Sultana",
        "Sadia Sharmeen Shatyi",
        "MD Azam Khan",
        "Joynal Abed"
      ],
      "abstract": "This study examines how Artificial Intelligence can aid in identifying and mitigating cyber threats in the U.S. across four key areas: intrusion detection, malware classification, phishing detection, and insider threat analysis. Each of these problems has its quirks, meaning there needs to be different approaches to each, so we matched the models to the shape of the problem. For intrusion detection, catching things like unauthorized access, we tested unsupervised anomaly detection methods. Isolation forests and deep autoencoders both gave us useful signals by picking up odd patterns in network traffic. When it came to malware detection, we leaned on ensemble models like Random Forest and XGBoost, trained on features pulled from files and traffic logs. Phishing was more straightforward. We fed standard classifiers (logistic regression, Random Forest, XGBoost) a mix of email and web-based features. These models handled the task surprisingly well. Phishing turned out to be the easiest problem to crack, at least with the data we had. There was a different story. We utilized an LSTM autoencoder to identify behavioral anomalies in user activity logs. It caught every suspicious behavior but flagged a lot of harmless ones too. That kind of model makes sense when the cost of missing a threat is high and you are willing to sift through some noise. What we saw across the board is that performance was not about stacking the most complex model. What mattered was how well the models structure matched the way the data behaved. When signals were strong and obvious, simple models worked fine. But for messier, more subtle threats, we needed something more adaptive, sequence models and anomaly detectors, though they brought their trade offs. The takeaway here is clear in cybersecurity, context drives the solution.",
      "publication_date": "2025-08-02T16:03:35+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "2508.01422v1"
    },
    {
      "title": "CLIProv: A Contrastive Log-to-Intelligence Multimodal Approach for   Threat Detection and Provenance Analysis",
      "authors": [
        "Jingwen Li",
        "Ru Zhang",
        "Jianyi Liu",
        "Wanguo Zhao"
      ],
      "abstract": "With the increasing complexity of cyberattacks, the proactive and forward-looking nature of threat intelligence has become more crucial for threat detection and provenance analysis. However, translating high-level attack patterns described in Tactics, Techniques, and Procedures (TTP) intelligence into actionable security policies remains a significant challenge. This challenge arises from the semantic gap between high-level threat intelligence and low-level provenance log. To address this issue, this paper introduces CLIProv, a novel approach for detecting threat behaviors in a host system. CLIProv employs a multimodal framework that leverages contrastive learning to align the semantics of provenance logs with threat intelligence, effectively correlating system intrusion activities with attack patterns. Furthermore, CLIProv formulates threat detection as a semantic search problem, identifying attack behaviors by searching for threat intelligence that is most semantically similar to the log sequence. By leveraging attack pattern information in threat intelligence, CLIProv identifies TTPs and generates complete and concise attack scenarios. Experimental evaluations on standard datasets show that CLIProv effectively identifies attack behaviors in system provenance logs, offering valuable references for potential techniques. Compared to state-of-the-art methods, CLIProv achieves higher precision and significantly improved detection efficiency.",
      "publication_date": "2025-07-12T04:20:00+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "2507.09133v1"
    },
    {
      "title": "Preventing Poisoning Attacks on AI based Threat Intelligence Systems",
      "authors": [
        "Nitika Khurana",
        "Sudip Mittal",
        "Anupam Joshi"
      ],
      "abstract": "As AI systems become more ubiquitous, securing them becomes an emerging challenge. Over the years, with the surge in online social media use and the data available for analysis, AI systems have been built to extract, represent and use this information. The credibility of this information extracted from open sources, however, can often be questionable. Malicious or incorrect information can cause a loss of money, reputation, and resources; and in certain situations, pose a threat to human life. In this paper, we use an ensembled semi-supervised approach to determine the credibility of Reddit posts by estimating their reputation score to ensure the validity of information ingested by AI systems. We demonstrate our approach in the cybersecurity domain, where security analysts utilize these systems to determine possible threats by analyzing the data scattered on social media websites, forums, blogs, etc.",
      "publication_date": "2018-07-19T13:40:37+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.SI"
      ],
      "arxiv_id": "1807.07418v1"
    },
    {
      "title": "Deep Reinforcement Learning for Cybersecurity Threat Detection and   Protection: A Review",
      "authors": [
        "Mohit Sewak",
        "Sanjay K. Sahay",
        "Hemant Rathore"
      ],
      "abstract": "The cybersecurity threat landscape has lately become overly complex. Threat actors leverage weaknesses in the network and endpoint security in a very coordinated manner to perpetuate sophisticated attacks that could bring down the entire network and many critical hosts in the network. Increasingly advanced deep and machine learning-based solutions have been used in threat detection and protection. The application of these techniques has been reviewed well in the scientific literature. Deep Reinforcement Learning has shown great promise in developing AI-based solutions for areas that had earlier required advanced human cognizance. Different techniques and algorithms under deep reinforcement learning have shown great promise in applications ranging from games to industrial processes, where it is claimed to augment systems with general AI capabilities. These algorithms have recently also been used in cybersecurity, especially in threat detection and endpoint protection, where these are showing state-of-the-art results. Unlike supervised machines and deep learning, deep reinforcement learning is used in more diverse ways and is empowering many innovative applications in the threat defense landscape. However, there does not exist any comprehensive review of these unique applications and accomplishments. Therefore, in this paper, we intend to fill this gap and provide a comprehensive review of the different applications of deep reinforcement learning in cybersecurity threat detection and protection.",
      "publication_date": "2022-06-06T16:42:00+00:00",
      "doi": "10.1007/978-3-030-97532-6_4",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "2206.02733v1"
    },
    {
      "title": "Advancing Security in AI Systems: A Novel Approach to Detecting   Backdoors in Deep Neural Networks",
      "authors": [
        "Khondoker Murad Hossain",
        "Tim Oates"
      ],
      "abstract": "In the rapidly evolving landscape of communication and network security, the increasing reliance on deep neural networks (DNNs) and cloud services for data processing presents a significant vulnerability: the potential for backdoors that can be exploited by malicious actors. Our approach leverages advanced tensor decomposition algorithms Independent Vector Analysis (IVA), Multiset Canonical Correlation Analysis (MCCA), and Parallel Factor Analysis (PARAFAC2) to meticulously analyze the weights of pre-trained DNNs and distinguish between backdoored and clean models effectively. The key strengths of our method lie in its domain independence, adaptability to various network architectures, and ability to operate without access to the training data of the scrutinized models. This not only ensures versatility across different application scenarios but also addresses the challenge of identifying backdoors without prior knowledge of the specific triggers employed to alter network behavior. We have applied our detection pipeline to three distinct computer vision datasets, encompassing both image classification and object detection tasks. The results demonstrate a marked improvement in both accuracy and efficiency over existing backdoor detection methods. This advancement enhances the security of deep learning and AI in networked systems, providing essential cybersecurity against evolving threats in emerging technologies.",
      "publication_date": "2024-03-13T03:10:11+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "2403.08208v1"
    }
  ]
}