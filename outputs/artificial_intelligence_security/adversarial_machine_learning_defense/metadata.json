{
  "processing_metadata": {
    "processed_at": "2025-08-07T09:34:32.141686+00:00",
    "processor_version": "1.0.0",
    "max_papers_limit": 50,
    "deduplication_enabled": true,
    "concept_extraction_enabled": true
  },
  "strategy_metadata": {
    "config_name": "artificial_intelligence_security",
    "strategy_name": "adversarial_machine_learning_defense",
    "papers_found": 1
  },
  "file_structure": {
    "papers_file": "papers.json",
    "metadata_file": "metadata.json",
    "concepts_file": "concepts.json",
    "hierarchy_file": "concept_hierarchy.json"
  },
  "last_download_date": "2025-08-07T09:34:32.141686+00:00",
  "downloaded_papers": {
    "title:adversarial machine learning: attacks, defenses, and open challenges": {
      "title": "Adversarial Machine Learning: Attacks, Defenses, and Open Challenges",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Adversarial_Machine_Learning:_Attacks,_Defenses,_and_Open_Challenges.pdf"
    },
    "title:detecting adversarial examples": {
      "title": "Detecting Adversarial Examples",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Detecting_Adversarial_Examples.pdf"
    },
    "title:adversarial backdoor defense in clip": {
      "title": "Adversarial Backdoor Defense in CLIP",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Adversarial_Backdoor_Defense_in_CLIP.pdf"
    },
    "title:privacy-preserving universal adversarial defense for black-box models": {
      "title": "Privacy-preserving Universal Adversarial Defense for Black-box Models",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Privacy-preserving_Universal_Adversarial_Defense_for_Black-box_Models.pdf"
    },
    "title:towards unified robustness against both backdoor and adversarial attacks": {
      "title": "Towards Unified Robustness Against Both Backdoor and Adversarial Attacks",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Towards_Unified_Robustness_Against_Both_Backdoor_and_Adversarial_Attacks.pdf"
    },
    "title:detecting adversarial data using perturbation forgery": {
      "title": "Detecting Adversarial Data using Perturbation Forgery",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Detecting_Adversarial_Data_using_Perturbation_Forgery.pdf"
    },
    "title:certified adversarial robustness of machine learning-based malware   detectors via (de)randomized smoothing": {
      "title": "Certified Adversarial Robustness of Machine Learning-based Malware   Detectors via (De)Randomized Smoothing",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Certified_Adversarial_Robustness_of_Machine_Learning-based_Malware___Detectors_via_(De)Randomized_Smoothing.pdf"
    },
    "title:adversarial sparse teacher: defense against distillation-based model   stealing attacks using adversarial examples": {
      "title": "Adversarial Sparse Teacher: Defense Against Distillation-Based Model   Stealing Attacks Using Adversarial Examples",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Adversarial_Sparse_Teacher:_Defense_Against_Distillation-Based_Model___Stealing_Attacks_Using_Adversarial_Examples.pdf"
    },
    "title:evasive hardware trojan through adversarial power trace": {
      "title": "Evasive Hardware Trojan through Adversarial Power Trace",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Evasive_Hardware_Trojan_through_Adversarial_Power_Trace.pdf"
    },
    "title:continual adversarial defense": {
      "title": "Continual Adversarial Defense",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Continual_Adversarial_Defense.pdf"
    },
    "title:defenses in adversarial machine learning: a survey": {
      "title": "Defenses in Adversarial Machine Learning: A Survey",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Defenses_in_Adversarial_Machine_Learning:_A_Survey.pdf"
    },
    "title:large language models are better adversaries: exploring generative   clean-label backdoor attacks against text classifiers": {
      "title": "Large Language Models Are Better Adversaries: Exploring Generative   Clean-Label Backdoor Attacks Against Text Classifiers",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Large_Language_Models_Are_Better_Adversaries:_Exploring_Generative___Clean-Label_Backdoor_Attacks_Against_Text_Classifiers.pdf"
    },
    "title:adversarial robustness unhardening via backdoor attacks in federated   learning": {
      "title": "Adversarial Robustness Unhardening via Backdoor Attacks in Federated   Learning",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Adversarial_Robustness_Unhardening_via_Backdoor_Attacks_in_Federated___Learning.pdf"
    },
    "title:language guided adversarial purification": {
      "title": "Language Guided Adversarial Purification",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Language_Guided_Adversarial_Purification.pdf"
    },
    "title:advancing adversarial robustness through adversarial logit update": {
      "title": "Advancing Adversarial Robustness Through Adversarial Logit Update",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Advancing_Adversarial_Robustness_Through_Adversarial_Logit_Update.pdf"
    },
    "title:adversarial feature map pruning for backdoor": {
      "title": "Adversarial Feature Map Pruning for Backdoor",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Adversarial_Feature_Map_Pruning_for_Backdoor.pdf"
    },
    "title:shared adversarial unlearning: backdoor mitigation by unlearning shared   adversarial examples": {
      "title": "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared   Adversarial Examples",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Shared_Adversarial_Unlearning:_Backdoor_Mitigation_by_Unlearning_Shared___Adversarial_Examples.pdf"
    },
    "title:atwm: defense against adversarial malware based on adversarial training": {
      "title": "ATWM: Defense against adversarial malware based on adversarial training",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/ATWM:_Defense_against_adversarial_malware_based_on_adversarial_training.pdf"
    },
    "title:denoising autoencoder-based defensive distillation as an adversarial   robustness algorithm": {
      "title": "Denoising Autoencoder-based Defensive Distillation as an Adversarial   Robustness Algorithm",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Denoising_Autoencoder-based_Defensive_Distillation_as_an_Adversarial___Robustness_Algorithm.pdf"
    },
    "title:graph adversarial immunization for certifiable robustness": {
      "title": "Graph Adversarial Immunization for Certifiable Robustness",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Graph_Adversarial_Immunization_for_Certifiable_Robustness.pdf"
    },
    "title:contributor-aware defenses against adversarial backdoor attacks": {
      "title": "Contributor-Aware Defenses Against Adversarial Backdoor Attacks",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Contributor-Aware_Defenses_Against_Adversarial_Backdoor_Attacks.pdf"
    },
    "title:a mask-based adversarial defense scheme": {
      "title": "A Mask-Based Adversarial Defense Scheme",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/A_Mask-Based_Adversarial_Defense_Scheme.pdf"
    },
    "title:the adversarial security mitigations of mmwave beamforming prediction   models using defensive distillation and adversarial retraining": {
      "title": "The Adversarial Security Mitigations of mmWave Beamforming Prediction   Models using Defensive Distillation and Adversarial Retraining",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/The_Adversarial_Security_Mitigations_of_mmWave_Beamforming_Prediction___Models_using_Defensive_Distillation_and_Adversarial_Retraining.pdf"
    },
    "title:certified federated adversarial training": {
      "title": "Certified Federated Adversarial Training",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Certified_Federated_Adversarial_Training.pdf"
    },
    "title:adversarial attacks on ml defense models competition": {
      "title": "Adversarial Attacks on ML Defense Models Competition",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Adversarial_Attacks_on_ML_Defense_Models_Competition.pdf"
    },
    "title:a synergetic attack against neural network classifiers combining   backdoor and adversarial examples": {
      "title": "A Synergetic Attack against Neural Network Classifiers combining   Backdoor and Adversarial Examples",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/A_Synergetic_Attack_against_Neural_Network_Classifiers_combining___Backdoor_and_Adversarial_Examples.pdf"
    },
    "title:evading adversarial example detection defenses with orthogonal projected   gradient descent": {
      "title": "Evading Adversarial Example Detection Defenses with Orthogonal Projected   Gradient Descent",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Evading_Adversarial_Example_Detection_Defenses_with_Orthogonal_Projected___Gradient_Descent.pdf"
    },
    "10.1109/MASS52906.2021.00032": {
      "title": "Certifiably-Robust Federated Adversarial Learning via Randomized   Smoothing",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Certifiably-Robust_Federated_Adversarial_Learning_via_Randomized___Smoothing.pdf"
    },
    "title:what doesn't kill you makes you robust(er): how to adversarially train   against data poisoning": {
      "title": "What Doesn't Kill You Makes You Robust(er): How to Adversarially Train   against Data Poisoning",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/What_Doesn't_Kill_You_Makes_You_Robust(er):_How_to_Adversarially_Train___against_Data_Poisoning.pdf"
    },
    "title:towards bridging the gap between empirical and certified robustness   against adversarial examples": {
      "title": "Towards Bridging the gap between Empirical and Certified Robustness   against Adversarial Examples",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Towards_Bridging_the_gap_between_Empirical_and_Certified_Robustness___against_Adversarial_Examples.pdf"
    },
    "title:omni: automated ensemble with unexpected models against adversarial   evasion attack": {
      "title": "Omni: Automated Ensemble with Unexpected Models against Adversarial   Evasion Attack",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Omni:_Automated_Ensemble_with_Unexpected_Models_against_Adversarial___Evasion_Attack.pdf"
    },
    "title:can we mitigate backdoor attack using adversarial detection methods?": {
      "title": "Can We Mitigate Backdoor Attack Using Adversarial Detection Methods?",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Can_We_Mitigate_Backdoor_Attack_Using_Adversarial_Detection_Methods?.pdf"
    },
    "title:encryption inspired adversarial defense for visual classification": {
      "title": "Encryption Inspired Adversarial Defense for Visual Classification",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Encryption_Inspired_Adversarial_Defense_for_Visual_Classification.pdf"
    },
    "title:certifying joint adversarial robustness for model ensembles": {
      "title": "Certifying Joint Adversarial Robustness for Model Ensembles",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Certifying_Joint_Adversarial_Robustness_for_Model_Ensembles.pdf"
    },
    "title:certified defenses for adversarial patches": {
      "title": "Certified Defenses for Adversarial Patches",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Certified_Defenses_for_Adversarial_Patches.pdf"
    },
    "title:unmask: adversarial detection and defense through robust feature   alignment": {
      "title": "UnMask: Adversarial Detection and Defense Through Robust Feature   Alignment",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/UnMask:_Adversarial_Detection_and_Defense_Through_Robust_Feature___Alignment.pdf"
    },
    "title:smoothed inference for adversarially-trained models": {
      "title": "Smoothed Inference for Adversarially-Trained Models",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Smoothed_Inference_for_Adversarially-Trained_Models.pdf"
    },
    "title:towards model-agnostic adversarial defenses using adversarially trained   autoencoders": {
      "title": "Towards Model-Agnostic Adversarial Defenses using Adversarially Trained   Autoencoders",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Towards_Model-Agnostic_Adversarial_Defenses_using_Adversarially_Trained___Autoencoders.pdf"
    },
    "10.1145/3319535.3354211": {
      "title": "Privacy Risks of Securing Machine Learning Models against Adversarial   Examples",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Privacy_Risks_of_Securing_Machine_Learning_Models_against_Adversarial___Examples.pdf"
    },
    "title:adversarial training for free!": {
      "title": "Adversarial Training for Free!",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Adversarial_Training_for_Free!.pdf"
    },
    "title:at-gan: an adversarial generator model for non-constrained adversarial   examples": {
      "title": "AT-GAN: An Adversarial Generator Model for Non-constrained Adversarial   Examples",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/AT-GAN:_An_Adversarial_Generator_Model_for_Non-constrained_Adversarial___Examples.pdf"
    },
    "title:can adversarial network attack be defended?": {
      "title": "Can Adversarial Network Attack be Defended?",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Can_Adversarial_Network_Attack_be_Defended?.pdf"
    },
    "title:efficient two-step adversarial defense for deep neural networks": {
      "title": "Efficient Two-Step Adversarial Defense for Deep Neural Networks",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Efficient_Two-Step_Adversarial_Defense_for_Deep_Neural_Networks.pdf"
    },
    "title:certified adversarial robustness with additive noise": {
      "title": "Certified Adversarial Robustness with Additive Noise",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Certified_Adversarial_Robustness_with_Additive_Noise.pdf"
    },
    "title:deepcloak: adversarial crafting as a defensive measure to cloak   processes": {
      "title": "DeepCloak: Adversarial Crafting As a Defensive Measure to Cloak   Processes",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/DeepCloak:_Adversarial_Crafting_As_a_Defensive_Measure_to_Cloak___Processes.pdf"
    },
    "title:adversarial robustness toolbox v1.0.0": {
      "title": "Adversarial Robustness Toolbox v1.0.0",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Adversarial_Robustness_Toolbox_v1.0.0.pdf"
    },
    "title:generating adversarial examples with adversarial networks": {
      "title": "Generating Adversarial Examples with Adversarial Networks",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Generating_Adversarial_Examples_with_Adversarial_Networks.pdf"
    },
    "title:ensemble adversarial training: attacks and defenses": {
      "title": "Ensemble Adversarial Training: Attacks and Defenses",
      "download_date": "2025-08-07T09:16:50.475888+00:00",
      "file_path": "pdfs/Ensemble_Adversarial_Training:_Attacks_and_Defenses.pdf"
    },
    "10.1145/3240765.3264699": {
      "title": "Defensive Dropout for Hardening Deep Neural Networks under Adversarial   Attacks",
      "download_date": "2025-08-07T09:33:46.333806+00:00",
      "file_path": "pdfs/Defensive_Dropout_for_Hardening_Deep_Neural_Networks_under_Adversarial___Attacks.pdf"
    },
    "10.1109/TIFS.2020.3003571": {
      "title": "Adversarial Deep Ensemble: Evasion Attacks and Defenses for Malware   Detection",
      "download_date": "2025-08-07T09:34:32.141686+00:00",
      "file_path": "pdfs/Adversarial_Deep_Ensemble:_Evasion_Attacks_and_Defenses_for_Malware___Detection.pdf"
    }
  }
}