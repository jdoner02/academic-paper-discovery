{
  "download_info": {
    "timestamp": "2025-08-07T16:37:53.340845+00:00",
    "strategy_name": "Incident Response and Recovery Optimization",
    "total_papers": 49,
    "download_directory": "outputs/cybersecurity_operations_research/incident_response_optimization/pdfs"
  },
  "papers": [
    {
      "title": "Two-stage battery recharge scheduling and vehicle-charger assignment   policy for dynamic electric dial-a-ride services",
      "authors": [
        "Tai-Yu Ma"
      ],
      "abstract": "Coordinating the charging scheduling of electric vehicles for dynamic dial-a-ride services is challenging considering charging queuing delays and stochastic customer demand. We propose a new two-stage solution approach to handle dynamic vehicle charging scheduling to minimize the costs of daily charging operations of the fleet. The approach comprises two components: daily vehicle charging scheduling and online vehicle-charger assignment. A new battery charge scheduling model is proposed to obtain the vehicle charging schedules by minimizing the costs of vehicle daily charging operations while satisfying vehicle driving needs to serve customers. In the second stage, an online vehicle-charger assignment model is developed to minimize the total vehicle idle time for charges by considering queuing delays at the level of chargers. An efficient Lagrangian relaxation algorithm is proposed to solve the large-scale vehicle-charger assignment problem with small optimality gaps. The approach is applied to a realistic dynamic dial-a-ride service case study in Luxembourg and compared with the nearest charging station charging policy and first-come-first-served minimum charging delay policy under different charging infrastructure scenarios. Our computational results show that the approach can achieve significant savings for the operator in terms of charging waiting times (-74.9%), charging times (-38.6%), and charged energy costs (-27.4%). A sensitivity analysis is conducted to evaluate the impact of the different model parameters, showing the scalability and robustness of the approach in a stochastic environment.",
      "publication_date": "2020-10-04T11:25:47+00:00",
      "doi": "10.1371/journal.pone.0251582",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "2010.01541v3"
    },
    {
      "title": "Emergent Incident Response for Unmanned Warehouses with Multi-agent   Systems*",
      "authors": [
        "Yibo Guo",
        "Mingxin Li",
        "Jingting Zong",
        "Mingliang Xu"
      ],
      "abstract": "Unmanned warehouses are an important part of logistics, and improving their operational efficiency can effectively enhance service efficiency. However, due to the complexity of unmanned warehouse systems and their susceptibility to errors, incidents may occur during their operation, most often in inbound and outbound operations, which can decrease operational efficiency. Hence it is crucial to to improve the response to such incidents. This paper proposes a collaborative optimization algorithm for emergent incident response based on Safe-MADDPG. To meet safety requirements during emergent incident response, we investigated the intrinsic hidden relationships between various factors. By obtaining constraint information of agents during the emergent incident response process and of the dynamic environment of unmanned warehouses on agents, the algorithm reduces safety risks and avoids the occurrence of chain accidents; this enables an unmanned system to complete emergent incident response tasks and achieve its optimization objectives: (1) minimizing the losses caused by emergent incidents; and (2) maximizing the operational efficiency of inbound and outbound operations during the response process. A series of experiments conducted in a simulated unmanned warehouse scenario demonstrate the effectiveness of the proposed method.",
      "publication_date": "2023-05-29T14:30:35+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.RO"
      ],
      "arxiv_id": "2305.18119v1"
    },
    {
      "title": "An optimization and simulation method for the home service assignment,   routing, and scheduling problem with stochastic travel time, service time,   and cancellation",
      "authors": [
        "Daniel Yamín",
        "Daniel Barahona",
        "Alfaima L. Solano-Blanco"
      ],
      "abstract": "In the Home Service Assignment, Routing, and Appointment scheduling (H-SARA) problem, a set of homogeneous service teams must visit a set of customers. The home service provider needs to decide how many teams to hire (i.e., sizing problem), how to assign service teams to customers (i.e., assignment problem), how to route service teams (i.e., vehicle routing problem),and how to schedule the appointment times for the customers (i.e., appointment scheduling problem) such that the total cost is minimized. To tackle the H-SARA problem, we propose an efficient solution method that comprises two stages. In the first stage, we present a column generation algorithm to solve the sizing, assignment, and routing problem. The algorithm is enhanced by a high-quality initial solution which is found using the route-first cluster-second principle and a polynomial-time 2-approximation algorithm. In the second stage, due to the stochastic nature of travel time, service time, and cancellation, we propose a simulation-driven approach to decide the appointment times such that a desired on-time arrival probability is achieved. To ensure the suitability of the simulation model, we discuss the characterization of the stochastic parameters. The proposed ideas can be embedded in different solution schemes, including a fast heuristic method that finds good solutions within seconds or a more elaborate algorithm to find near-optimal solutions at the expense of longer computational time. At last, we provide a high-level flexible decision support tool implemented in AIMMS.",
      "publication_date": "2021-09-20T17:03:38+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "2109.09693v1"
    },
    {
      "title": "Delay-Constrained Input-Queued Switch",
      "authors": [
        "Lei Deng",
        "Wing Shing Wong",
        "Po-Ning Chen",
        "Yunghsiang S. Han",
        "Hanxu Hou"
      ],
      "abstract": "In this paper, we study the delay-constrained input-queued switch where each packet has a deadline and it will expire if it is not delivered before its deadline. Such new scenario is motivated by the proliferation of real-time applications in multimedia communication systems, tactile Internet, networked controlled systems, and cyber-physical systems. The delay-constrained input-queued switch is completely different from the well-understood delay-unconstrained one and thus poses new challenges. We focus on three fundamental problems centering around the performance metric of timely throughput: (i) how to characterize the capacity region? (ii) how to design a feasibility/throughput-optimal scheduling policy? and (iii) how to design a network-utility-maximization scheduling policy? We use three different approaches to solve these three fundamental problems. The first approach is based on Markov Decision Process (MDP) theory, which can solve all three problems. However, it suffers from the curse of dimensionality. The second approach breaks the curse of dimensionality by exploiting the combinatorial features of the problem. It gives a new capacity region characterization with only a polynomial number of linear constraints. The third approach is based on the framework of Lyapunov optimization, where we design a polynomial-time maximum-weight T-disjoint-matching scheduling policy which is proved to be feasibility/throughput-optimal. Our three approaches apply to the frame-synchronized traffic pattern but our MDP-based approach can be extended to more general traffic patterns.",
      "publication_date": "2018-09-08T15:41:27+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.NI"
      ],
      "arxiv_id": "1809.02826v3"
    },
    {
      "title": "Resource Provisioning and Scheduling Algorithm for Meeting Cost and   Deadline-Constraints of Scientific Workflows in IaaS Clouds",
      "authors": [
        "Amit Gajbhiye",
        "Shailendra Singh"
      ],
      "abstract": "Infrastructure as a Service model of cloud computing is a desirable platform for the execution of cost and deadline constrained workflow applications as the elasticity of cloud computing allows large-scale complex scientific workflow applications to scale dynamically according to their deadline requirements. However, scheduling of these multitask workflow jobs in a distributed computing environment is a computationally hard multi-objective combinatorial optimization problem. The critical challenge is to schedule the workflow tasks whilst meeting user quality of service (QoS) requirements and the application's deadline. The existing research work not only fails to address this challenge but also do not incorporate the basic principles of elasticity and heterogeneity of computing resources in cloud environment. In this paper, we propose a resource provisioning and scheduling algorithm to schedule the workflow applications on IaaS clouds to meet application deadline constraints while optimizing the execution cost. The proposed algorithm is based on the nature-inspired population based Intelligent Water Drop (IWD) optimization algorithm. The experimental results in the simulated environment of CloudSim with four real-world workflow applications demonstrates that IWD algorithm schedules workflow tasks with optimized cost within the specified deadlines. Moreover, the IWD algorithm converges fast to near optimal solution.",
      "publication_date": "2018-06-06T19:30:14+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.DC"
      ],
      "arxiv_id": "1806.02397v1"
    },
    {
      "title": "Multi-Resource Parallel Query Scheduling and Optimization",
      "authors": [
        "Minos Garofalakis",
        "Yannis Ioannidis"
      ],
      "abstract": "Scheduling query execution plans is a particularly complex problem in shared-nothing parallel systems, where each site consists of a collection of local time-shared (e.g., CPU(s) or disk(s)) and space-shared (e.g., memory) resources and communicates with remote sites by message-passing. Earlier work on parallel query scheduling employs either (a) one-dimensional models of parallel task scheduling, effectively ignoring the potential benefits of resource sharing, or (b) models of globally accessible resource units, which are appropriate only for shared-memory architectures, since they cannot capture the affinity of system resources to sites. In this paper, we develop a general approach capturing the full complexity of scheduling distributed, multi-dimensional resource units for all forms of parallelism within and across queries and operators. We present a level-based list scheduling heuristic algorithm for independent query tasks (i.e., physical operator pipelines) that is provably near-optimal for given degrees of partitioned parallelism (with a worst-case performance ratio that depends on the number of time-shared and space-shared resources per site and the granularity of the clones). We also propose extensions to handle blocking constraints in logical operator (e.g., hash-join) pipelines and bushy query plans as well as on-line task arrivals (e.g., in a dynamic or multi-query execution environment). Experiments with our scheduling algorithms implemented on top of a detailed simulation model verify their effectiveness compared to existing approaches in a realistic setting. Based on our analytical and experimental results, we revisit the open problem of designing efficient cost models for parallel query optimization and propose a solution that captures all the important parameters of parallel execution.",
      "publication_date": "2014-03-30T10:15:06+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.DB"
      ],
      "arxiv_id": "1403.7729v1"
    },
    {
      "title": "Optimal Scheduling Control in Fluid Models of General $n\\times n$   Input-Queued Switches",
      "authors": [
        "Yingdong Lu",
        "Mark S. Squillante",
        "Tonghoon Suk"
      ],
      "abstract": "Most of the early input-queued switch research focused on establishing throughput optimality of the max-weight scheduling policy, with some recent research showing that max-weight scheduling is optimal with respect to total expected delay asymptotically in the heavy-traffic regime. However, the question of delay-optimal scheduling in input-queued switches remains open in general, as does the question of delay-optimal scheduling under more general objective functions. To gain fundamental insights into these very difficult problems, we consider a fluid model of $n \\times n$ input-queued switches with associated fluid-flow costs, and we derive an optimal scheduling control policy to an infinite horizon discounted control problem with a general linear objective function of fluid cost. Our optimal policy coincides with the $c\\mu$-rule in certain parameter domains. More generally, due to the input-queued switch constraints, the optimal policy takes the form of the solution to a flow maximization problem, after we identify the Lagrangian multipliers of some key constraints through carefully designed algorithms. Computational experiments demonstrate the benefits of our optimal scheduling policy over variants of max-weight scheduling within fluid models of input-queued switches.",
      "publication_date": "2019-10-30T04:27:02+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "1910.13657v2"
    },
    {
      "title": "Target-Following Online Resource Allocation Using Proxy Assignments",
      "authors": [
        "Chamsi Hssaine",
        "Huseyin Topaloglu",
        "Garrett van Ryzin"
      ],
      "abstract": "We study a target-following variation of online resource allocation. As in classical resource allocation, the decision-maker must assign sequentially arriving jobs to one of multiple available resources. However, in addition to the assignment costs incurred from these decisions, the decision-maker is also penalized for deviating from exogenously given, nonstationary target allocations throughout the horizon. The goal is to minimize the total expected assignment and deviation penalty costs incurred throughout the horizon when the distribution of assignment costs is unknown. In contrast to traditional online resource allocation, in our setting the timing of allocation decisions is critical due to the nonstationarity of allocation targets. Examples of practical problems that fit this framework include many physical resource settings where capacity is time-varying, such as manual warehouse processes where staffing levels change over time, and assignment of packages to outbound trucks whose departure times are scheduled throughout the day. We first show that naive extensions of state-of-the-art algorithms for classical resource allocation problems can fail dramatically when applied to target-following resource allocation. We then propose a novel ``proxy assignment\" primal-dual algorithm for the target-following online resource allocation problem that uses current arrivals to simulate the effect of future arrivals. We prove that our algorithm incurs the optimal $O(\\sqrt{T})$ regret bound when the assignment costs of the arriving jobs are drawn i.i.d. from a fixed distribution. We demonstrate the practical performance of our approach by conducting numerical experiments on synthetic datasets, as well as real-world datasets from retail fulfillment operations.",
      "publication_date": "2024-12-16T19:40:17+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "2412.12321v1"
    },
    {
      "title": "Adaptive large neighborhood search for a personnel task scheduling   problem with task selection and parallel task assignments",
      "authors": [
        "Martin Gutjahr",
        "Sophie N. Parragh",
        "Fabien Tricoire"
      ],
      "abstract": "Motivated by a real-world application, we model and solve a complex staff scheduling problem. Tasks are to be assigned to workers for supervision. Multiple tasks can be covered in parallel by a single worker, with worker shifts being flexible within availabilities. Each worker has a different skill set, enabling them to cover different tasks. Tasks require assignment according to priority and skill requirements. The objective is to maximize the number of assigned tasks weighted by their priorities, while minimizing assignment penalties. We develop an adaptive large neighborhood search (ALNS) algorithm, relying on tailored destroy and repair operators. It is tested on benchmark instances derived from real-world data and compared to optimal results obtained by means of a commercial MIP-solver. Furthermore, we analyze the impact of considering three additional alternative objective functions. When applied to large-scale company data, the developed ALNS outperforms the previously applied solution approach.",
      "publication_date": "2023-02-09T08:43:06+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.DM"
      ],
      "arxiv_id": "2302.04494v1"
    },
    {
      "title": "Differentiable Discrete Event Simulation for Queuing Network Control",
      "authors": [
        "Ethan Che",
        "Jing Dong",
        "Hongseok Namkoong"
      ],
      "abstract": "Queuing network control is essential for managing congestion in job-processing systems such as service systems, communication networks, and manufacturing processes. Despite growing interest in applying reinforcement learning (RL) techniques, queueing network control poses distinct challenges, including high stochasticity, large state and action spaces, and lack of stability. To tackle these challenges, we propose a scalable framework for policy optimization based on differentiable discrete event simulation. Our main insight is that by implementing a well-designed smoothing technique for discrete event dynamics, we can compute pathwise policy gradients for large-scale queueing networks using auto-differentiation software (e.g., Tensorflow, PyTorch) and GPU parallelization. Through extensive empirical experiments, we observe that our policy gradient estimators are several orders of magnitude more accurate than typical REINFORCE-based estimators. In addition, We propose a new policy architecture, which drastically improves stability while maintaining the flexibility of neural-network policies. In a wide variety of scheduling and admission control tasks, we demonstrate that training control policies with pathwise gradients leads to a 50-1000x improvement in sample efficiency over state-of-the-art RL methods. Unlike prior tailored approaches to queueing, our methods can flexibly handle realistic scenarios, including systems operating in non-stationary environments and those with non-exponential interarrival/service times.",
      "publication_date": "2024-09-05T17:53:54+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.LG"
      ],
      "arxiv_id": "2409.03740v1"
    },
    {
      "title": "Capacity Allocation in Queuing Systems with Preferred Service Completion   Times",
      "authors": [
        "Bahar Çavdar",
        "Tuğçe Işık"
      ],
      "abstract": "Retailers use a variety of mechanisms to enable sales and delivery. A relatively new offering by companies is curbside pickup where customers purchase goods online, schedule a pickup time, and come to a pickup facility to receive their orders. To model this new service structure, we consider a queuing system where each arriving job has a preferred service completion time. Unlike most queuing systems, we make a strategic decision for when to serve each job based on their requested times and the associated costs. We assume that all jobs must be served before or on their requested time period, and the jobs are outsourced when the capacity is insufficient. Costs are incurred for jobs that are outsourced or served early. For small systems, we show that optimal capacity allocation policies are of threshold type. For general systems, we devise heuristic policies based on similar threshold structures. Our numerical study investigates the performance of the heuristics developed and shows the robustness of them with respect to several service parameters. Our results provide insights on how the optimal long-run average costs change based on the capacity of the system, the length of the planning horizon, cost parameters and the order pattern.",
      "publication_date": "2020-05-26T03:14:16+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "2005.12499v1"
    },
    {
      "title": "Staff Scheduling for Demand-Responsive Services",
      "authors": [
        "Debsankha Manik",
        "Rico Raber"
      ],
      "abstract": "Staff scheduling is a well-known problem in operations research and finds its application at hospitals, airports, supermarkets, and many others. Its goal is to assign shifts to staff members such that a certain objective function, e.g. revenue, is maximized. Meanwhile, various constraints of the staff members and the organization need to be satisfied. Typically in staff scheduling problems, there are hard constraints on the minimum number of employees that should be available at specific points of time. Often multiple hard constraints guaranteeing the availability of specific number of employees with different roles need to be considered. Staff scheduling for demand-responsive services, such as, e.g., ride-pooling and ride-hailing services, differs in a key way from this: There are often no hard constraints on the minimum number of employees needed at fixed points in time. Rather, the number of employees working at different points in time should vary according to the demand at those points in time. Having too few employees at a point in time results in lost revenue, while having too many employees at a point in time results in not having enough employees at other points in time, since the total personnel-hours are limited. The objective is to maximize the total reward generated over a planning horizon, given a monotonic relationship between the number of shifts active at a point in time and the instantaneous reward generated at that point in time. This key difference makes it difficult to use existing staff scheduling algorithms for planning shifts in demand-responsive services. In this article, we present a novel approach for modelling and solving staff scheduling problems for demand-responsive services that optimizes for the relevant reward function.",
      "publication_date": "2024-06-27T10:00:17+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.DM"
      ],
      "arxiv_id": "2406.19053v1"
    },
    {
      "title": "Dependency-Aware CAV Task Scheduling via Diffusion-Based Reinforcement   Learning",
      "authors": [
        "Xiang Cheng",
        "Zhi Mao",
        "Ying Wang",
        "Wen Wu"
      ],
      "abstract": "In this paper, we propose a novel dependency-aware task scheduling strategy for dynamic unmanned aerial vehicle-assisted connected autonomous vehicles (CAVs). Specifically, different computation tasks of CAVs consisting of multiple dependency subtasks are judiciously assigned to nearby CAVs or the base station for promptly completing tasks. Therefore, we formulate a joint scheduling priority and subtask assignment optimization problem with the objective of minimizing the average task completion time. The problem aims at improving the long-term system performance, which is reformulated as a Markov decision process. To solve the problem, we further propose a diffusion-based reinforcement learning algorithm, named Synthetic DDQN based Subtasks Scheduling, which can make adaptive task scheduling decision in real time. A diffusion model-based synthetic experience replay is integrated into the reinforcement learning framework, which can generate sufficient synthetic data in experience replay buffer, thereby significantly accelerating convergence and improving sample efficiency. Simulation results demonstrate the effectiveness of the proposed algorithm on reducing task completion time, comparing to benchmark schemes.",
      "publication_date": "2024-11-27T11:07:31+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.AI"
      ],
      "arxiv_id": "2411.18230v1"
    },
    {
      "title": "Reshi: Recommending Resources for Scientific Workflow Tasks on   Heterogeneous Infrastructures",
      "authors": [
        "Jonathan Bader",
        "Fabian Lehmann",
        "Alexander Groth",
        "Lauritz Thamsen",
        "Dominik Scheinert",
        "Jonathan Will",
        "Ulf Leser",
        "Odej Kao"
      ],
      "abstract": "Scientific workflows typically comprise a multitude of different processing steps which often are executed in parallel on different partitions of the input data. These executions, in turn, must be scheduled on the compute nodes of the computational infrastructure at hand. This assignment is complicated by the facts that (a) tasks typically have highly heterogeneous resource requirements and (b) in many infrastructures, compute nodes offer highly heterogeneous resources. In consequence, predictions of the runtime of a given task on a given node, as required by many scheduling algorithms, are often rather imprecise, which can lead to sub-optimal scheduling decisions.   We propose Reshi, a method for recommending task-node assignments during workflow execution that can cope with heterogeneous tasks and heterogeneous nodes. Reshi approaches the problem as a regression task, where task-node pairs are modeled as feature vectors over the results of dedicated micro benchmarks and past task executions. Based on these features, Reshi trains a regression tree model to rank and recommend nodes for each ready-to-run task, which can be used as input to a scheduler. For our evaluation, we benchmarked 27 AWS machine types using three representative workflows. We compare Reshi's recommendations with three state-of-the-art schedulers. Our evaluation shows that Reshi outperforms HEFT by a mean makespan reduction of 7.18% and 18.01% assuming a mean task runtime prediction error of 15%.",
      "publication_date": "2022-08-16T18:47:51+00:00",
      "doi": "10.1109/IPCCC55026.2022.9894299",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.DC"
      ],
      "arxiv_id": "2208.07905v2"
    },
    {
      "title": "Stochastic project management: Multiple projects with multi-skilled   human resources",
      "authors": [
        "Thomas Felberbauer",
        "Walter Gutjahr",
        "Karl Doerner"
      ],
      "abstract": "This paper presents two stochastic optimization approaches for simultaneous project scheduling and personnel planning, extending a deterministic model previously developed by Heimerl and Kolisch. For the problem of assigning work packages to multi-skilled human resources with heterogeneous skills, the uncertainty on work package processing times is addressed. In the case where the required capacity exceeds the available capacity of internal resources, external human resources are used. The objective is to minimize the expected external costs. The first solution approach is a 'matheuristic' based on a decomposition of the problem into a project scheduling subproblem and a staffing subproblem. An iterated local search procedure determines the project schedules, while the staffing subproblem is solved by means of the Frank-Wolfe algorithm for convex optimization. The second solution approach is Sample Average Approximation where, based on sampled scenarios, the deterministic equivalent problem is solved through mixed integer programming. Experimental results for synthetically generated test instances inspired by a real-world situation are provided, and some managerial insights are derived.",
      "publication_date": "2018-12-03T11:06:59+00:00",
      "doi": "10.1007/s10951-018-0592-y",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "1812.00664v1"
    },
    {
      "title": "Scheduling of Dependent Tasks Application using Random Search Technique",
      "authors": [
        "Deepak. c. vegda",
        "Harshad. B. Prajapati"
      ],
      "abstract": "Since beginning of Grid computing, scheduling of dependent tasks application has attracted attention of researchers due to NP-Complete nature of the problem. In Grid environment, scheduling is deciding about assignment of tasks to available resources. Scheduling in Grid is challenging when the tasks have dependencies and resources are heterogeneous. The main objective in scheduling of dependent tasks is minimizing make-span. Due to NP-complete nature of scheduling problem, exact solutions cannot generate schedule efficiently. Therefore, researchers apply heuristic or random search techniques to get optimal or near to optimal solution of such problems. In this paper, we show how Genetic Algorithm can be used to solve dependent task scheduling problem. We describe how initial population can be generated using random assignment and height based approaches. We also present design of crossover and mutation operators to enable scheduling of dependent tasks application without violating dependency constraints. For implementation of GA based scheduling, we explore and analyze SimGrid and GridSim simulation toolkits. From results, we found that SimGrid is suitable, as it has support of SimDag API for DAG applications. We found that GA based approach can generate schedule for dependent tasks application in reasonable time while trying to minimize make-span.",
      "publication_date": "2013-04-15T05:04:31+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.DC"
      ],
      "arxiv_id": "1304.3980v1"
    },
    {
      "title": "Demand-Adaptive Route Planning and Scheduling for Urban Hub-based   High-Capacity Mobility-on-Demand Services",
      "authors": [
        "Xinwu Qian",
        "Jiawei Xue",
        "Satish V. Ukkusuri"
      ],
      "abstract": "In this study, we propose a three-stage framework for the planning and scheduling of high-capacity mobility-on-demand services (e.g., micro transit and flexible transit) at urban activity hubs. The proposed framework consists of (1) the route generation step to and from the activity hub with connectivity to existing transit systems, and (2) the robust route scheduling step which determines the vehicle assignment and route headway under demand uncertainty. Efficient exact and heuristic algorithms are developed for identifying the minimum number of routes that maximize passenger coverage, and a matching scheme is proposed to combine routes to and from the hub into roundtrips optimally. With the generated routes, the robust route scheduling problem is formulated as a two-stage robust optimization problem. Model reformulations are introduced to solve the robust optimization problem into the global optimum. In this regard, the proposed framework presents both algorithmic and analytic solutions for developing the hub-based transit services in response to the varying passenger demand over a short-time period. To validate the effectiveness of the proposed framework, comprehensive numerical experiments are conducted for planning the HHMoD services at the JFK airport in New York City (NYC). The results show the superior performance of the proposed route generation algorithm to maximize the citywide coverage more efficiently. The results also demonstrate the cost-effectiveness of the robust route schedules under normal demand conditions and against worst-case-oriented realizations of passenger demand.",
      "publication_date": "2020-08-25T07:22:11+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "2008.10855v1"
    },
    {
      "title": "How Workflow Engines Should Talk to Resource Managers: A Proposal for a   Common Workflow Scheduling Interface",
      "authors": [
        "Fabian Lehmann",
        "Jonathan Bader",
        "Friedrich Tschirpke",
        "Lauritz Thamsen",
        "Ulf Leser"
      ],
      "abstract": "Scientific workflow management systems (SWMSs) and resource managers together ensure that tasks are scheduled on provisioned resources so that all dependencies are obeyed, and some optimization goal, such as makespan minimization, is achieved. In practice, however, there is no clear separation of scheduling responsibilities between an SWMS and a resource manager because there exists no agreed-upon separation of concerns between their different components. This has two consequences. First, the lack of a standardized API to exchange scheduling information between SWMSs and resource managers hinders portability. It incurs costly adaptations when a component should be replaced by a different one (e.g., an SWMS with another SWMS on the same resource manager). Second, due to overlapping functionalities, current installations often actually have two schedulers, both making partial scheduling decisions under incomplete information, leading to suboptimal workflow scheduling.   In this paper, we propose a simple REST interface between SWMSs and resource managers, which allows any SWMS to pass dynamic workflow information to a resource manager, enabling maximally informed scheduling decisions. We provide an implementation of this API as an example, using Nextflow as an SWMS and Kubernetes as a resource manager. Our experiments with nine real-world workflows show that this strategy reduces makespan by up to 25.1% and 10.8% on average compared to the standard Nextflow/Kubernetes configuration. Furthermore, a more widespread implementation of this API would enable leaner code bases, a simpler exchange of components of workflow systems, and a unified place to implement new scheduling algorithms.",
      "publication_date": "2023-02-15T13:35:52+00:00",
      "doi": "10.1109/CCGrid57682.2023.00025",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.DC"
      ],
      "arxiv_id": "2302.07652v3"
    },
    {
      "title": "LSTFCoDel: CoDel with LSTF-Style Priority Queuing",
      "authors": [
        "Christen Ford"
      ],
      "abstract": "Congestion control is vastly important in computer networks. Arising naturally from the bursty nature of Internet traffic, congestion plagues not only the network edge, but also the network core. Many remedies have been proposed to fight congestion; active queue management (AQM) is one such proposal. AQM seeks to prevent congestion by actively avoiding it. Some queuing disciplines such as Random Early Detection (RED) will prematurely drop a random packet (with some probability) when the queue nears capacity to signal the sender to back off. However, RED utilizes queue length as a mechanism to indicate congestion. On the other hand, the Controlled Delay (CoDel) queuing discipline uses queuing delay as an indication of congestion. The problem with both RED and CoDel are that they indiscriminately treat all packets the same. Normally implemented using a FIFO queue, CoDel simply enqueues and dequeues packets in a first-come, first-served manner. Priority queuing can be carefully utilized to selectively service packets utilizing the very same metric CoDel uses for AQM, queuing delay. That said, Least Slack Time First (LSTF), a multi-processor scheduling algorithm employs priority scheduling, which coincidentally, is also based on delay. In the context of computer networks LSTF can be applied in the control plane or in the data plane. At the control plane, LSTF functions across the entire network, but in doing so requires all intermediary routers to implement it; LSTF also requires support at the packet level in terms of a slack entry. Within the data plane, LSTF can be implemented as a queuing mechanism based on delay spent in the router (just like CoDel AQM). This paper applies data plane level LSTF to CoDel AQM to enable delay-based packet classification within the confines of the CoDel AQM algorithm.",
      "publication_date": "2020-07-02T20:32:19+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.NI"
      ],
      "arxiv_id": "2007.01375v1"
    },
    {
      "title": "Deployment of Leader-Follower Automated Vehicle Systems for Smart Work   Zone Applications with a Queuing-based Traffic Assignment Approach",
      "authors": [
        "Qing Tang",
        "Xianbiao Hu"
      ],
      "abstract": "The emerging technology of the Autonomous Truck Mounted Attenuator (ATMA), a leader-follower style vehicle system, utilizes connected and automated vehicle capabilities to enhance safety during transportation infrastructure maintenance in work zones. However, the speed difference between ATMA vehicles and general vehicles creates a moving bottleneck that reduces capacity and increases queue length, resulting in additional delays. The different routes taken by ATMA cause diverse patterns of time-varying capacity drops, which may affect the user equilibrium traffic assignment and lead to different system costs. This manuscript focuses on optimizing the routing for ATMA vehicles in a network to minimize the system cost associated with the slow-moving operation.   To achieve this, a queuing-based traffic assignment approach is proposed to identify the system cost caused by the ATMA system. A queuing-based time-dependent (QBTD) travel time function, considering capacity drop, is introduced and applied in the static user equilibrium traffic assignment problem, with a result of adding dynamic characteristics. Subsequently, we formulate the queuing-based traffic assignment problem and solve it using a modified path-based algorithm. The methodology is validated using a small-size and a large-size network and compared with two benchmark models to analyze the benefit of capacity drop modeling and QBTD travel time function. Furthermore, the approach is applied to quantify the impact of different routes on the traffic system and identify an optimal route for ATMA vehicles performing maintenance work. Finally, sensitivity analysis is conducted to explore how the impact changes with variations in traffic demand and capacity reduction.",
      "publication_date": "2023-07-23T16:35:05+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "eess.SY"
      ],
      "arxiv_id": "2308.03764v1"
    },
    {
      "title": "Joint Data Compression, Secure Multi-Part Collaborative Task Offloading   and Resource Assignment in Ultra-Dense Networks",
      "authors": [
        "Tianqing Zhou",
        "Kangle Liu",
        "Dong Qin",
        "Xuan Li",
        "Nan Jiang",
        "Chunguo Li"
      ],
      "abstract": "To enhance resource utilization and address interference issues in ultra-dense networks with mobile edge computing (MEC), a resource utilization approach is first introduced, which integrates orthogonal frequency division multiple access (OFDMA) and non-orthogonal multiple access (NOMA). Then, to minimize the energy consumed by ultra-densely deployed small base stations (SBSs) while ensuring proportional assignment of computational resources and the constraints related to processing delay and security breach cost, the joint optimization of channel selection, the number of subchannels, secure service assignment, multi-step computation offloading, device association, data compression (DC) control, power control, and frequency band partitioning is done for minimizing network-wide energy consumption (EC). Given that the current problem is nonlinear and involves integral optimization parameters, we have devised an adaptive genetic water wave optimization (AGWWO) algorithm by improving the traditional water wave optimization (WWO) algorithm using genetic operations. After that, the computational complexity, convergence, and parallel implementation of AGWWO algorithm are analyzed. Simulation results reveal that this algorithm effectively reduces network-wide EC while guaranteeing the constraints of processing delay and security breach cost.",
      "publication_date": "2024-10-16T03:13:42+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.IT"
      ],
      "arxiv_id": "2410.12186v1"
    },
    {
      "title": "Optimizing UAV Trajectory for Emergency Response Operations under Real   3D Environments: Integrating Priority Levels and LoS Constraints",
      "authors": [
        "Mohammad Taghi Dabiri",
        "Mazen Hasna",
        "Saud Althunibat",
        "Khalid Qaraqe"
      ],
      "abstract": "Unmanned Aerial Vehicles (UAVs) have emerged as a critical component in next-generation wireless networks, particularly for disaster recovery scenarios, due to their flexibility, mobility, and rapid deployment capabilities. This paper focuses on optimizing UAV trajectories to ensure effective communication in disaster-stricken areas using terahertz (THz) links. We address specific challenges such as energy consumption, user priority levels, and navigating complex urban environments to maintain Line of Sight (LoS) connections amidst 3D obstacles. Our contributions include the development of a detailed modeling approach using online 3D map data, the formulation of an optimal trajectory optimization problem, and the proposal of a Genetic Algorithm (GA)-based method alongside an enhanced heuristic algorithm for faster convergence. Through 3D simulations, we demonstrate the trade-off between minimizing total service time and prioritizing higher-weight nodes, showing the impact of different priority weight factors on the trajectory time. The proposed algorithms are evaluated using real-world data from the West Bay area of Doha, Qatar, demonstrating their effectiveness in optimizing UAV trajectories for emergency response.",
      "publication_date": "2024-08-14T14:41:13+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "eess.SP"
      ],
      "arxiv_id": "2408.07589v1"
    },
    {
      "title": "Joint QoS-aware and Cost-efficient Task Scheduling for Fog-Cloud   Resources in a Volunteer Computing System",
      "authors": [
        "Farooq Hoseiny",
        "Sadoon Azizi",
        "Mohammad Shojafar",
        "Rahim Tafazolli"
      ],
      "abstract": "Volunteer computing is an Internet-based distributed computing system in which volunteers share their extra available resources to manage large-scale tasks. However, computing devices in a Volunteer Computing System (VCS) are highly dynamic and heterogeneous in terms of their processing power, monetary cost, and data transferring latency. To ensure both the high Quality of Service (QoS) and low cost for different requests, all of the available computing resources must be used efficiently. Task scheduling is an NP-hard problem that is considered one of the main critical challenges in a heterogeneous VCS. Due to this, in this paper, we design two task scheduling algorithms for VCSs, named Min-CCV and Min-V. The main goal of the proposed algorithms is jointly minimizing the computation, communication and delay violation cost for the Internet of Things (IoT) requests. Our extensive simulation results show that proposed algorithms are able to allocate tasks to volunteer fog/cloud resources more efficiently than the state-of-the-art. Specifically, our algorithms improve the deadline satisfaction task rates by around 99.5% and decrease the total cost between 15 to 53% in comparison with the genetic-based algorithm.",
      "publication_date": "2021-04-28T18:58:51+00:00",
      "doi": "10.1145/3418501",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.DC"
      ],
      "arxiv_id": "2104.13974v1"
    },
    {
      "title": "Dynamic Scheduling Strategies for Resource Optimization in Computing   Environments",
      "authors": [
        "Xiaoye Wang"
      ],
      "abstract": "The rapid development of cloud-native architecture has promoted the widespread application of container technology, but the optimization problems in container scheduling and resource management still face many challenges. This paper proposes a container scheduling method based on multi-objective optimization, which aims to balance key performance indicators such as resource utilization, load balancing and task completion efficiency. By introducing optimization models and heuristic algorithms, the scheduling strategy is comprehensively improved, and experimental verification is carried out using the real Google Cluster Data dataset. The experimental results show that compared with traditional static rule algorithms and heuristic algorithms, the optimized scheduling scheme shows significant advantages in resource utilization, load balancing and burst task completion efficiency. This shows that the proposed method can effectively improve resource management efficiency and ensure service quality and system stability in complex dynamic cloud environments. At the same time, this paper also explores the future development direction of scheduling algorithms in multi-tenant environments, heterogeneous cloud computing, and cross-edge and cloud collaborative computing scenarios, and proposes research prospects for energy consumption optimization, adaptive scheduling and fairness. The research results not only provide a theoretical basis and practical reference for container scheduling under cloud-native architecture, but also lay a foundation for further realizing intelligent and efficient resource management.",
      "publication_date": "2024-12-23T05:43:17+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.DC"
      ],
      "arxiv_id": "2412.17301v1"
    },
    {
      "title": "Cost and Reliability Aware Scheduling of Workflows Across Multiple   Clouds with Security Constraints",
      "authors": [
        "Atherve Tekawade",
        "Suman Banerjee"
      ],
      "abstract": "Many real-world scientific workflows can be represented by a Directed Acyclic Graph (DAG), where each node represents a task and a directed edge signifies a dependency between two tasks. Due to the increasing computational resource requirements of these workflows, they are deployed on multi-cloud systems for execution. In this paper, we propose a scheduling algorithm that allocates resources to the tasks present in the workflow using an efficient list-scheduling approach based on the parameters cost, processing time, and reliability. Next, for a given a task-resource mapping, we propose a cipher assignment algorithm that assigns security services to edges responsible for transferring data in time-optimal manner subject to a given security constraint. The proposed algorithms have been analyzed to understand their time and space requirements. We implement the proposed scheduling and cipher assignment algorithm and experimented with two real-world scientific workflows namely Epigenomics and Cybershake. We compare the performance of the proposed scheduling algorithm with the state-of-art evolutionary methods. We observe that our method outperforms the state-of-art methods always in terms of cost and reliability, and is inferior in terms of makespan in some cases.",
      "publication_date": "2023-04-01T13:50:11+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.DC"
      ],
      "arxiv_id": "2304.00313v1"
    },
    {
      "title": "IncidentResponseGPT: Generating Traffic Incident Response Plans with   Generative Artificial Intelligence",
      "authors": [
        "Artur Grigorev",
        "Adriana-Simona Mihaita Khaled Saleh",
        "Yuming Ou"
      ],
      "abstract": "The proposed IncidentResponseGPT framework - a novel system that applies generative artificial intelligence (AI) to potentially enhance the efficiency and effectiveness of traffic incident response. This model allows for synthesis of region-specific incident response guidelines and generates incident response plans adapted to specific area, aiming to expedite decision-making for traffic management authorities. This approach aims to accelerate incident resolution times by suggesting various recommendations (e.g. optimal rerouting strategies, estimating resource needs) to minimize the overall impact on the urban traffic network. The system suggests specific actions, including dynamic lane closures, optimized rerouting and dispatching appropriate emergency resources. We utilize the Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) to rank generated response plans based on criteria like impact minimization and resource efficiency based on their proximity to an human-proposed solution.",
      "publication_date": "2024-04-29T09:45:46+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.LG"
      ],
      "arxiv_id": "2404.18550v4"
    },
    {
      "title": "Tracking and Assigning Jobs to a Markov Machine",
      "authors": [
        "Subhankar Banerjee",
        "Sennur Ulukus"
      ],
      "abstract": "We consider a time-slotted communication system with a machine, a cloud server, and a sampler. Job requests from the users are queued on the server to be completed by the machine. The machine has two states, namely, a busy state and a free state. The server can assign a job to the machine in a first-in-first-served manner. If the machine is free, it completes the job request from the server; otherwise, it drops the request. Upon dropping a job request, the server is penalized. When the machine is in the free state, the machine can get into the busy state with an internal job. When the server does not assign a job request to the machine, the state of the machine evolves as a symmetric Markov chain. If the machine successfully accepts the job request from the server, the state of the machine goes to the busy state and follows a different dynamics compared to the dynamics when the machine goes to the busy state due to an internal job. The sampler samples the state of the machine and sends it to the server via an error-free channel. Thus, the server can estimate the state of the machine, upon receiving an update from the source. If the machine is in the free state but the estimated state at the server is busy, the sampler pays a cost. We incorporate the concept of the age of incorrect information to model the cost of the sampler. We aim to find an optimal sampling policy such that the cost of the sampler plus the penalty on the machine gets minimized. We formulate this problem in a Markov decision process framework and find how an optimal policy changes with several associated parameters. We show that a threshold policy is optimal for this problem. We show a necessary and sufficient condition for a threshold policy to be optimal. Finally, we find the optimal threshold without bounding the state space.",
      "publication_date": "2025-02-20T18:04:09+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.IT"
      ],
      "arxiv_id": "2502.14783v1"
    },
    {
      "title": "Optimal Design of Queuing Systems via Compositional Stochastic   Programming",
      "authors": [
        "Srujan Teja Thomdapu",
        "Ketan Rajawat"
      ],
      "abstract": "Well-designed queuing systems form the backbone of modern communications, distributed computing, and content delivery architectures. Designs balancing infrastructure costs and user experience indices require tools from teletraffic theory and operations research. A standard approach to designing such systems involves formulating optimization problems that strive to maximize the pertinent utility functions while adhering to quality-of-service and other physical constraints. In many cases, formulating such problems necessitates making simplistic assumptions on arrival and departure processes to keep the problem simple. This work puts forth a stochastic optimization framework for designing queuing systems where the exogenous processes may have arbitrary and unknown distributions. We show that many such queuing design problems can generally be formulated as stochastic optimization problems where the objective and constraint are non-linear functions of expectations. The compositional structure obviates the use of classical stochastic approximation approaches where the stochastic gradients are often required to be unbiased. To this end, a constrained stochastic compositional gradient descent algorithm is proposed that utilizes a tracking step for the expected value functions. The non-asymptotic performance of the proposed algorithm is characterized via its iteration complexity. Numerical tests allow us to validate the theoretical results and demonstrate the efficacy of the proposed algorithm.",
      "publication_date": "2019-07-20T08:13:15+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.IT"
      ],
      "arxiv_id": "1907.08774v1"
    },
    {
      "title": "Markov Decision Process and Approximate Dynamic Programming for a   Patient Assignment Scheduling problem",
      "authors": [
        "Malgorzata M. O'Reilly",
        "Sebastian Krasnicki",
        "James Montgomery",
        "Mojtaba Heydar",
        "Richard Turner",
        "Pieter Van Dam",
        "Peter Maree"
      ],
      "abstract": "We study the Patient Assignment Scheduling (PAS) problem in a random environment that arises in the management of patient flow in the hospital systems, due to the stochastic nature of the arrivals as well as the Length of Stay distribution. We develop a Markov Decision Process (MDP) which aims to assign the newly arrived patients in an optimal way so as to minimise the total expected long-run cost per unit time over an infinite horizon. We assume Poisson arrival rates that depend on patient types, and Length of Stay distributions that depend on whether patients stay in their primary wards or not. Since the instances of realistic size of this problem are not easy to solve, we develop numerical methods based on Approximate Dynamic Programming. We illustrate the theory with numerical examples with parameters obtained by fitting to data from a tertiary referral hospital in Australia, and demonstrate the application potential of our methodology under practical considerations.",
      "publication_date": "2024-06-26T06:47:31+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "2406.18618v1"
    },
    {
      "title": "Optimal fast charging station locations for electric ridesharing service   with online vehicle-charging station assignment",
      "authors": [
        "Tai-Yu Ma",
        "Simin Xie"
      ],
      "abstract": "Electrified shared mobility services need to handle charging infrastructure planning and manage their daily charging operations to minimize total charging operation time and cost. However, existing studies tend to address these problems separately. A new online vehicle-charging assignment model is proposed and integrated into the fast charging location problem for dynamic ridesharing services using electric vehicles. The latter is formulated as a bi-level optimization problem to minimize the fleet's daily charging operation time. A surrogate-assisted optimization approach is proposed to solve the combinatorial optimization problem efficiently. The proposed model is tested on a realistic flexible bus service in Luxembourg. The results show that the proposed online charging policy can effectively reduce the charging delays of the fleet compared to the state-of-the-art methods. With 10 additional DC fast chargers installed, charging operation time can be reduced up to 27.8% when applying the online charging policy under the test scenarios.",
      "publication_date": "2020-08-13T14:55:07+00:00",
      "doi": "10.1016/j.trd.2020.102682",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "2008.05949v2"
    },
    {
      "title": "Multi-agricultural Machinery Collaborative Task Assignment Based on   Improved Genetic Hybrid Optimization Algorithm",
      "authors": [
        "Haohao Du"
      ],
      "abstract": "To address the challenges of delayed scheduling information, heavy reliance on manual labour, and low operational efficiency in traditional large-scale agricultural machinery operations, this study proposes a method for multi-agricultural machinery collaborative task assignment based on an improved genetic hybrid optimisation algorithm. The proposed method establishes a multi-agricultural machinery task allocation model by combining the path pre-planning of a simulated annealing algorithm and the static task allocation of a genetic algorithm. By sequentially fusing these two algorithms, their respective shortcomings can be overcome, and their advantages in global and local search can be utilised. Consequently, the search capability of the population is enhanced, leading to the discovery of more optimal solutions. Then, an adaptive crossover operator is constructed according to the task assignment model, considering the capacity, path cost, and time of agricultural machinery; two-segment coding and multi-population adaptive mutation are used to assign tasks to improve the diversity of the population and enhance the exploration ability of the population; and to improve the global optimisation ability of the hybrid algorithm, a 2-Opt local optimisation operator and an Circle modification algorithm are introduced. Finally, simulation experiments were conducted in MATLAB to evaluate the performance of the multi-agricultural machinery collaborative task assignment based on the improved genetic hybrid algorithm. The algorithm's capabilities were assessed through comparative analysis in the simulation trials. The results demonstrate that the developed hybrid algorithm can effectively reduce path costs, and the efficiency of the assignment outcomes surpasses that of the classical genetic algorithm. This approach proves particularly suitable for addressing large-scale task allocation problems.",
      "publication_date": "2023-12-07T12:42:40+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.NE"
      ],
      "arxiv_id": "2312.04264v1"
    },
    {
      "title": "Flowshop Machine Scheduling: Markov Modeling, Optimal Schedules and   Heuristics",
      "authors": [
        "Samah A. M. Ghanem"
      ],
      "abstract": "Flowshop machine scheduling has been of main interest in several applications where the timing of its processes plays a fundamental role in the utilization of system resources. Addressing the optimal sequencing of the jobs when equivalent failures across machines exist is a decision of particular relevance to the general scheduling problem. Such failures allow for unpredictable time consumption and improper utilization of the machines. Therefore, it is of particular relevance to address the problem with new modeling approaches considering the parallel and sequential components of the manufacturing process under equivalent failure in the jobs at each machine. In this paper, we propose a novel Markov chain to model the N/ M/P/F permutation flowshop. We analyze the time cost encountered due to M consecutive machine equivalent failures in processing N jobs. We derive new closed form expressions of the completion time under such setup. We extend the Markov model into its underlying components, providing another new Markov model with processes that dont encounter failures and compare both systems. We provide new insights on job ordering decision rules and new approaches in a set of proposed algorithms that provide novel optimal and heuristic methods that provides optimal or near optimal schedules. We derive closed form expressions that divide per machine CT and per machine processing and waiting times. Further, we provide a novel scheme that proves intimate connections between such time components and the maximum number of rounds per machine that allows optimal utilization of the machines in one CT.",
      "publication_date": "2025-03-20T21:13:04+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.PF"
      ],
      "arxiv_id": "2504.20048v1"
    },
    {
      "title": "Optimal Stochastic Dynamic Scheduling for Managing Community Recovery   from Natural Hazards",
      "authors": [
        "Saeed Nozhati",
        "Yugandhar Sarkale",
        "Edwin K. P. Chong",
        "Bruce R. Ellingwood"
      ],
      "abstract": "Following the occurrence of an extreme natural or man-made event, community recovery management should aim at providing optimal restoration policies for a community over a planning horizon. Calculating such optimal restoration polices in the presence of uncertainty poses significant challenges for community leaders. Stochastic scheduling for several interdependent infrastructure systems is a difficult control problem with huge decision spaces. The Markov decision process (MDP)-based optimization approach proposed in this study incorporates different sources of uncertainties to compute the restoration policies. The computation of optimal scheduling schemes using our method employs the rollout algorithm, which provides an effective computational tool for optimization problems dealing with real-world large-scale networks and communities. We apply the proposed methodology to a realistic community recovery problem, where different decision-making objectives are considered. Our approach accommodates current restoration strategies employed in recovery management. Our computational results indicate that the restoration policies calculated using our techniques significantly outperform the current recovery strategies. Finally, we study the applicability of our method to address different risk attitudes of policymakers, which include risk-neutral and risk-averse attitudes in the community recovery management.",
      "publication_date": "2018-12-26T01:02:08+00:00",
      "doi": "10.1016/j.ress.2019.106627",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.SY"
      ],
      "arxiv_id": "1812.10194v1"
    },
    {
      "title": "Fair Scheduling in Networks Through Packet Election",
      "authors": [
        "Srikanth Jagabathula",
        "Devavrat Shah"
      ],
      "abstract": "We consider the problem of designing a fair scheduling algorithm for discrete-time constrained queuing networks. Each queue has dedicated exogenous packet arrivals. There are constraints on which queues can be served simultaneously. This model effectively describes important special instances like network switches, interference in wireless networks, bandwidth sharing for congestion control and traffic scheduling in road roundabouts. Fair scheduling is required because it provides isolation to different traffic flows; isolation makes the system more robust and enables providing quality of service. Existing work on fairness for constrained networks concentrates on flow based fairness. As a main result, we describe a notion of packet based fairness by establishing an analogy with the ranked election problem: packets are voters, schedules are candidates and each packet ranks the schedules based on its priorities. We then obtain a scheduling algorithm that achieves the described notion of fairness by drawing upon the seminal work of Goodman and Markowitz (1952). This yields the familiar Maximum Weight (MW) style algorithm. As another important result we prove that algorithm obtained is throughput optimal. There is no reason a priori why this should be true, and the proof requires non-traditional methods.",
      "publication_date": "2008-08-19T05:33:35+00:00",
      "doi": "10.1109/TIT.2010.2103851",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.IT"
      ],
      "arxiv_id": "0808.2530v2"
    },
    {
      "title": "Joint Optimization of Continuous Variables and Priority Assignments for   Real-Time Systems with Black-box Schedulability Constraints",
      "authors": [
        "Sen Wang",
        "Dong Li",
        "Shao-Yu Huang",
        "Xuanliang Deng",
        "Ashrarul H. Sifat",
        "Changhee Jung",
        "Ryan Williams",
        "Haibo Zeng"
      ],
      "abstract": "In real-time systems optimization, designers often face a challenging problem posed by the non-convex and non-continuous schedulability conditions, which may even lack an analytical form to understand their properties. To tackle this challenging problem, we treat the schedulability analysis as a black box that only returns true/false results. We propose a general and scalable framework to optimize real-time systems, named Numerical Optimizer with Real-Time Highlight (NORTH). NORTH is built upon the gradient-based active-set methods from the numerical optimization literature but with new methods to manage active constraints for the non-differentiable schedulability constraints. In addition, we also generalize NORTH to NORTH+, to collaboratively optimize certain types of discrete variables (e.g., priority assignments, categorical variables) with continuous variables based on numerical optimization algorithms. We demonstrate the algorithm performance with two example applications: energy minimization based on dynamic voltage and frequency scaling (DVFS), and optimization of control system performance. In these experiments, NORTH achieved $10^2$ to $10^5$ times speed improvements over state-of-the-art methods while maintaining similar or better solution quality. NORTH+ outperforms NORTH by 30% with similar algorithm scalability. Both NORTH and NORTH+ support black-box schedulability analysis, ensuring broad applicability.",
      "publication_date": "2024-01-06T19:19:06+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "eess.SY"
      ],
      "arxiv_id": "2401.03284v2"
    },
    {
      "title": "Joint Task Assignment and Resource Allocation for D2D-Enabled   Mobile-Edge Computing",
      "authors": [
        "Hong Xing",
        "Liang Liu",
        "Jie Xu",
        "Arumugam Nallanathan"
      ],
      "abstract": "With the proliferation of computation-extensive and latency-critical applications in the 5G and beyond networks, mobile-edge computing (MEC) or fog computing, which provides cloud-like computation and/or storage capabilities at the network edge, is envisioned to reduce computation latency as well as to conserve energy for wireless devices (WDs). This paper studies a novel device-to-device (D2D)-enabled multi-helper MEC system, in which a local user solicits its nearby WDs serving as helpers for cooperative computation. We assume a time division multiple access (TDMA) transmission protocol, under which the local user offloads the tasks to multiple helpers and downloads the results from them over orthogonal pre-scheduled time slots. Under this setup, we minimize the computation latency by optimizing the local user's task assignment jointly with the time and rate for task offloading and results downloading, as well as the computation frequency for task execution, subject to individual energy and computation capacity constraints at the local user and the helpers. However, the formulated problem is a mixed-integer non-linear program (MINLP) that is difficult to solve. To tackle this challenge, we propose an efficient algorithm by first relaxing the original problem into a convex one, and then constructing a suboptimal task assignment solution based on the obtained optimal one. Next, we consider a benchmark scheme that endows the WDs with their maximum computation capacities. To further reduce the implementation complexity, we also develop a heuristic scheme based on the greedy task assignment. Finally, numerical results validate the effectiveness of our proposed algorithm, as compared against the heuristic scheme and other benchmark ones without either joint optimization of radio and computation resources or task assignment design.",
      "publication_date": "2019-02-26T15:57:39+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.IT"
      ],
      "arxiv_id": "1902.10017v1"
    },
    {
      "title": "Facility Location with Congestion and Priority in Drone-Based Emergency   Delivery",
      "authors": [
        "Xin Wang",
        "Ruiwei Jiang",
        "Mingyao Qi"
      ],
      "abstract": "Thanks to their fast delivery, reduced traffic restrictions, and low manpower need, drones have been increasingly deployed to deliver time-critical materials, such as medication, blood, and exam kits, in emergency situations. This paper considers a facility location model of using drones as mobile servers in emergency delivery. The model jointly optimizes the location of facilities, the capacity of drones deployed at opened facilities, and the allocation of demands, with an objective of equitable response times among all demand sites. To this end, we employ queues to model the system congestion of drone requests and consider three queuing disciplines: non-priority, static priority, and dynamic priority. For each discipline, we approximate the model as a mixed-integer second-order conic program (MISOCP), which can readily be solved in commercial solvers. We conduct extensive computational experiments to demonstrate the effectiveness and accuracy of our approach. Additionally, we compare the system performance under the three queuing disciplines and various problem parameters, from which we produce operational recommendations to decision makers in emergency delivery.",
      "publication_date": "2022-06-07T08:27:47+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "2206.03103v1"
    },
    {
      "title": "An SMDP-Based Approach to Thermal-Aware Task Scheduling in NoC-based   MPSoC platforms",
      "authors": [
        "Farnaz Niknia",
        "Kiamehr Rezaee",
        "Vesal Hakami"
      ],
      "abstract": "One efficient approach to control chip-wide thermal distribution in multi-core systems is the optimization of online assignments of tasks to processing cores. Online task assignment, however, faces several uncertainties in real-world Systems and does not show a deterministic nature. In this paper, we consider the operation of a thermal-aware task scheduler, dispatching tasks from an arrival queue as well as setting the voltage and frequency of the processing cores to optimize the mean temperature margin of the entire chip (i.e., cores as well as the NoC routers). We model the decision process of the task scheduler as a semi-Markov decision problem (SMDP). Then, to solve the formulated SMDP, we propose two reinforcement learning algorithms that are capable of computing the optimal task assignment policy without requiring the statistical knowledge of the stochastic dynamics underlying the system states. The proposed algorithms also rely on function approximation techniques to handle the infinite length of the task queue as well as the continuous nature of temperature readings. Compared to related research, the simulation results show a nearly 6 Kelvin reduction in system average peak temperature and 66 milliseconds decrease in mean task service time.",
      "publication_date": "2020-09-06T20:43:53+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.DC"
      ],
      "arxiv_id": "2009.02813v1"
    },
    {
      "title": "An Optimal Application-Aware Resource Block Scheduling in LTE",
      "authors": [
        "Tugba Erpek",
        "Ahmed Abdelhadi",
        "T. Charles Clancy"
      ],
      "abstract": "In this paper, we introduce an approach for application-aware resource block scheduling of elastic and inelastic adaptive real-time traffic in fourth generation Long Term Evolution (LTE) systems. The users are assigned to resource blocks. A transmission may use multiple resource blocks scheduled over frequency and time. In our model, we use logarithmic and sigmoidal-like utility functions to represent the users applications running on different user equipments (UE)s. We present an optimal problem with utility proportional fairness policy, where the fairness among users is in utility percentage (i.e user satisfaction with the service) of the corresponding applications. Our objective is to allocate the resources to the users with priority given to the adaptive real-time application users. In addition, a minimum resource allocation for users with elastic and inelastic traffic should be guaranteed. Every user subscribing for the mobile service should have a minimum quality-of-service (QoS) with a priority criterion. We prove that our scheduling policy exists and achieves the maximum. Therefore the optimal solution is tractable. We present a centralized scheduling algorithm to allocate evolved NodeB (eNodeB) resources optimally with a priority criterion. Finally, we present simulation results for the performance of our scheduling algorithm and compare our results with conventional proportional fairness approaches. The results show that the user satisfaction is higher with our proposed method.",
      "publication_date": "2014-05-29T03:03:56+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.NI"
      ],
      "arxiv_id": "1405.7446v1"
    },
    {
      "title": "Optimal Fixed Priority Scheduling in Multi-Stage Multi-Resource   Distributed Real-Time Systems",
      "authors": [
        "Niraj Kumar",
        "Chuanchao Gao",
        "Arvind Easwaran"
      ],
      "abstract": "This work studies fixed priority (FP) scheduling of real-time jobs with end-to-end deadlines in a distributed system. Specifically, given a multi-stage pipeline with multiple heterogeneous resources of the same type at each stage, the problem is to assign priorities to a set of real-time jobs with different release times to access a resource at each stage of the pipeline subject to the end-to-end deadline constraints. Note, in such a system, jobs may compete with different sets of jobs at different stages of the pipeline depending on the job-to-resource mapping. To this end, following are the two major contributions of this work. We show that an OPA-compatible schedulability test based on the delay composition algebra can be constructed, which we then use with an optimal priority assignment algorithm to compute a priority ordering. Further, we establish the versatility of pairwise priority assignment in such a multi-stage multi-resource system, compared to a total priority ordering. In particular, we show that a pairwise priority assignment may be feasible even if a priority ordering does not exist. We propose an integer linear programming formulation and a scalable heuristic to compute a pairwise priority assignment. We also show through simulation experiments that the proposed approaches can be used for the holistic scheduling of real-time jobs in edge computing systems.",
      "publication_date": "2024-03-20T08:53:35+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.DC"
      ],
      "arxiv_id": "2403.13411v1"
    },
    {
      "title": "A Cost-Driven Fuzzy Scheduling Strategy for Intelligent Workflow   Decision Making Systems in Uncertain Edge-Cloud Environments",
      "authors": [
        "Bing Lin",
        "Chaowei Lin",
        "Xing Chen"
      ],
      "abstract": "Workflow decision making is critical to performing many practical workflow applications. Scheduling in edge-cloud environments can address the high complexity problem of workflow applications, while decreasing the data transmission delay between the cloud and end devices. However, because of the heterogeneous resources in edge-cloud environments and the complicated data dependencies among the tasks in a workflow, significant challenges for workflow scheduling remain, including the selection of an optimal tasks-servers solution from the possible numerous combinations. The existing studies have been mainly done subject to rigorous conditions without fluctuations, ignoring the fact that workflow scheduling is typically present in uncertain environments. In this study, we focus on reducing the execution cost of workflow applications mainly caused by task computation and data transmission, while satisfying the workflow deadline in uncertain edge-cloud environments. The Triangular Fuzzy Numbers (TFNs) are adopted to represent the task processing time and data transferring time. A cost-driven fuzzy scheduling strategy based on an Adaptive Discrete Particle Swarm Optimization (ADPSO) algorithm is proposed, which employs the operators of Genetic Algorithm (GA). This strategy introduces the randomly two-point crossover operator, neighborhood mutation operator, and adaptive multipoint mutation operator of GA to effectively avoid converging on local optima. The experimental results show that our strategy can effectively reduce the workflow execution cost in uncertain edge-cloud environments, compared with other benchmark solutions.",
      "publication_date": "2021-07-03T10:54:58+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.DC"
      ],
      "arxiv_id": "2107.01405v4"
    },
    {
      "title": "Adversarial Task Assignment",
      "authors": [
        "Chen Hajaj",
        "Yevgeniy Vorobeychik"
      ],
      "abstract": "The problem of assigning tasks to workers is of long-standing fundamental importance. Examples of this include the classical problem of assigning computing tasks to nodes in a distributed computing environment, assigning jobs to robots, and crowdsourcing. Extensive research into this problem generally addresses important issues such as uncertainty and incentives. However, the problem of adversarial tampering with the task assignment process has not received as much attention.   We are concerned with a particular adversarial setting where an attacker may target a set of workers in order to prevent the tasks assigned to these workers from being completed. When all tasks are homogeneous, we provide an efficient algorithm for computing the optimal assignment. When tasks are heterogeneous, we show that the adversarial assignment problem is NP-Hard, and present an algorithm for solving it approximately. Our theoretical results are accompanied by extensive experiments showing the effectiveness of our algorithms.",
      "publication_date": "2018-04-27T16:52:16+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.GT"
      ],
      "arxiv_id": "1804.11221v2"
    },
    {
      "title": "Numerical study on the deadline-concerning priority queuing model",
      "authors": [
        "Hang-Hyun Jo"
      ],
      "abstract": "The Barab\\'asi's priority queuing model [A.-L. Barab\\'asi, Nature \\textbf{435}, 207 (2005)] and its variants have been extensively studied to understand heavy-tailed distributions of the inter-event times and the response times observed in various empirical analyses of human dynamics. In this paper, we focus on the effects of deadlines assigned to the tasks in a queue of fixed size on the response-time distributions. Here, the response time is defined as the time interval between the arrival and the execution of the task. We propose a deadline-concerning priority queuing model, in which as the deadline approaches, the priority is adjusted using the inverse of the remaining time to the deadline. By performing the numerical simulations, we find that the power-law exponent characterizing the response-time distributions is less than $1$ under the deterministic selection protocol while it has the value of $1$ under the nondeterministic selection protocol.",
      "publication_date": "2021-05-31T06:26:36+00:00",
      "doi": "10.1007/s40042-021-00219-7",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "physics.soc-ph"
      ],
      "arxiv_id": "2105.14718v1"
    },
    {
      "title": "Data-Aware Approximate Workflow Scheduling",
      "authors": [
        "Dengpan Yin",
        "Tevfik Kosar"
      ],
      "abstract": "Optimization of data placement in complex scientific workflows has become very crucial since the large amounts of data generated by these workflows significantly increases the turnaround time of the end-to-end application. It is almost impossible to make an optimal scheduling for the end-to-end workflow without considering the intermediate data movement. In order to reduce the complexity of the workflow-scheduling problem, most of the existing work constrains the problem space by some unrealistic assumptions, which result in non-optimal scheduling in practice. In this study, we propose a genetic data-aware algorithm for the end-to-end workflow scheduling problem. Distinct from the past research, we develop a novel data-aware evaluation function for each chromosome, a common augmenting crossover operator and a simple but effective mutation operator. Our experiments on different workflow structures show that the proposed GA based approach gives a scheduling close to the optimal one.",
      "publication_date": "2018-05-26T15:41:55+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.DC"
      ],
      "arxiv_id": "1805.10499v1"
    },
    {
      "title": "A Markov Decision Model for Adaptive Scheduling of Stored Scalable   Videos",
      "authors": [
        "Chao Chen",
        "Robert W. Heath Jr",
        "Alan C. Bovik",
        "Gustavo de Veciana"
      ],
      "abstract": "We propose two scheduling algorithms that seek to optimize the quality of scalably coded videos that have been stored at a video server before transmission.} The first scheduling algorithm is derived from a Markov Decision Process (MDP) formulation developed here. We model the dynamics of the channel as a Markov chain and reduce the problem of dynamic video scheduling to a tractable Markov decision problem over a finite state space. Based on the MDP formulation, a near-optimal scheduling policy is computed that minimize the mean square error. Using insights taken from the development of the optimal MDP-based scheduling policy, the second proposed scheduling algorithm is an online scheduling method that only requires easily measurable knowledge of the channel dynamics, and is thus viable in practice. Simulation results show that the performance of both scheduling algorithms is close to a performance upper bound also derived in this paper.",
      "publication_date": "2012-09-10T17:19:45+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.MM"
      ],
      "arxiv_id": "1209.2067v2"
    },
    {
      "title": "Scheduling Deep Learning Jobs in Multi-Tenant GPU Clusters via Wise   Resource Sharing",
      "authors": [
        "Yizhou Luo",
        "Qiang Wang",
        "Shaohuai Shi",
        "Jiaxin Lai",
        "Shuhan Qi",
        "Jiajia Zhang",
        "Xuan Wang"
      ],
      "abstract": "Deep learning (DL) has demonstrated significant success across diverse fields, leading to the construction of dedicated GPU accelerators within GPU clusters for high-quality training services. Efficient scheduler designs for such clusters are vital to reduce operational costs and enhance resource utilization. While recent schedulers have shown impressive performance in optimizing DL job performance and cluster utilization through periodic reallocation or selection of GPU resources, they also encounter challenges such as preemption and migration overhead, along with potential DL accuracy degradation. Nonetheless, few explore the potential benefits of GPU sharing to improve resource utilization and reduce job queuing times. Motivated by these insights, we present a job scheduling model allowing multiple jobs to share the same set of GPUs without altering job training settings. We introduce SJF-BSBF (shortest job first with best sharing benefit first), a straightforward yet effective heuristic scheduling algorithm. SJF-BSBF intelligently selects job pairs for GPU resource sharing and runtime settings (sub-batch size and scheduling time point) to optimize overall performance while ensuring DL convergence accuracy through gradient accumulation. In experiments with both physical DL workloads and trace-driven simulations, even as a preemption-free policy, SJF-BSBF reduces the average job completion time by 27-33\\% relative to the state-of-the-art preemptive DL schedulers. Moreover, SJF-BSBF can wisely determine the optimal resource sharing settings, such as the sharing time point and sub-batch size for gradient accumulation, outperforming the aggressive GPU sharing approach (baseline SJF-FFS policy) by up to 17\\% in large-scale traces.",
      "publication_date": "2024-07-18T01:30:49+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.DC"
      ],
      "arxiv_id": "2407.13088v1"
    },
    {
      "title": "An Efficient Max-Min Resource Allocator and Task Scheduling Algorithm in   Cloud Computing Environment",
      "authors": [
        "J. Kok Konjaang",
        "J. Y. Maipan-uku",
        "Kumangkem Kennedy Kubuga"
      ],
      "abstract": "Cloud computing is a new archetype that provides dynamic computing services to cloud users through the support of datacenters that employs the services of datacenter brokers which discover resources and assign them Virtually. The focus of this research is to efficiently optimize resource allocation in the cloud by exploiting the Max-Min scheduling algorithm and enhancing it to increase efficiency in terms of completion time (makespan). This is key to enhancing the performance of cloud scheduling and narrowing the performance gap between cloud service providers and cloud resources consumers/users. The current Max-Min algorithm selects tasks with maximum execution time on a faster available machine or resource that is capable of giving minimum completion time. The concern of this algorithm is to give priority to tasks with maximum execution time first before assigning those with the minimum execution time for the purpose of minimizing makespan. The drawback of this algorithm is that, the execution of tasks with maximum execution time first may increase the makespan, and leads to a delay in executing tasks with minimum execution time if the number of tasks with maximum execution time exceeds that of tasks with minimum execution time, hence the need to improve it to mitigate the delay in executing tasks with minimum execution time. CloudSim is used to compare the effectiveness of the improved Max-Min algorithm with the traditional one. The experimented results show that the improved algorithm is efficient and can produce better makespan than Max-Min and DataAware.",
      "publication_date": "2016-11-27T15:29:24+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.DC"
      ],
      "arxiv_id": "1611.08864v1"
    },
    {
      "title": "Optimal Task Assignment to Heterogeneous Federated Learning Devices",
      "authors": [
        "Laércio Lima Pilla"
      ],
      "abstract": "Federated Learning provides new opportunities for training machine learning models while respecting data privacy. This technique is based on heterogeneous devices that work together to iteratively train a model while never sharing their own data. Given the synchronous nature of this training, the performance of Federated Learning systems is dictated by the slowest devices, also known as stragglers. In this paper, we investigate the problem of minimizing the duration of Federated Learning rounds by controlling how much data each device uses for training. We formulate this problem as a makespan minimization problem with identical, independent, and atomic tasks that have to be assigned to heterogeneous resources with non-decreasing cost functions while respecting lower and upper limits of tasks per resource. Based on this formulation, we propose a polynomial-time algorithm named OLAR and prove that it provides optimal schedules. We evaluate OLAR in an extensive experimental evaluation using simulation that includes comparisons to other algorithms from the state of the art and new extensions to them. Our results indicate that OLAR provides optimal solutions with a small execution time. They also show that the presence of lower and upper limits of tasks per resource erase any benefits that suboptimal heuristics could provide in terms of algorithm execution time.",
      "publication_date": "2020-10-01T07:58:48+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.AI"
      ],
      "arxiv_id": "2010.00239v1"
    },
    {
      "title": "Scheduling with Outliers",
      "authors": [
        "Anupam Gupta",
        "Ravishankar Krishnaswamy",
        "Amit Kumar",
        "Danny Segev"
      ],
      "abstract": "In classical scheduling problems, we are given jobs and machines, and have to schedule all the jobs to minimize some objective function. What if each job has a specified profit, and we are no longer required to process all jobs -- we can schedule any subset of jobs whose total profit is at least a (hard) target profit requirement, while still approximately minimizing the objective function?   We refer to this class of problems as scheduling with outliers. This model was initiated by Charikar and Khuller (SODA'06) on the minimum max-response time in broadcast scheduling. We consider three other well-studied scheduling objectives: the generalized assignment problem, average weighted completion time, and average flow time, and provide LP-based approximation algorithms for them. For the minimum average flow time problem on identical machines, we give a logarithmic approximation algorithm for the case of unit profits based on rounding an LP relaxation; we also show a matching integrality gap. For the average weighted completion time problem on unrelated machines, we give a constant factor approximation. The algorithm is based on randomized rounding of the time-indexed LP relaxation strengthened by the knapsack-cover inequalities. For the generalized assignment problem with outliers, we give a simple reduction to GAP without outliers to obtain an algorithm whose makespan is within 3 times the optimum makespan, and whose cost is at most (1 + \\epsilon) times the optimal cost.",
      "publication_date": "2009-06-10T21:22:22+00:00",
      "doi": "10.1007/978-3-642-03685-9_12",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.DS"
      ],
      "arxiv_id": "0906.2020v1"
    }
  ]
}