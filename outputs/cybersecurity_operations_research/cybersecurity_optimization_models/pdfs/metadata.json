{
  "download_info": {
    "timestamp": "2025-08-07T16:33:30.530608+00:00",
    "strategy_name": "Cybersecurity Investment and Resource Optimization",
    "total_papers": 48,
    "download_directory": "outputs/cybersecurity_operations_research/cybersecurity_optimization_models/pdfs"
  },
  "papers": [
    {
      "title": "Uncertainty in Cyber Security Investments",
      "authors": [
        "Andrew Fielder",
        "Sandra Konig",
        "Emmanouil Panaousis",
        "Stefan Schauer",
        "Stefan Rass"
      ],
      "abstract": "When undertaking cyber security risk assessments, we must assign numeric values to metrics to compute the final expected loss that represents the risk that an organization is exposed to due to cyber threats. Even if risk assessment is motivated from real-world observations and data, there is always a high chance of assigning inaccurate values due to different uncertainties involved (e.g., evolving threat landscape, human errors) and the natural difficulty of quantifying risk per se. Our previous work has proposed a model and a software tool that empowers organizations to compute optimal cyber security strategies given their financial constraints, i.e., available cyber security budget. We have also introduced a general game-theoretic model with uncertain payoffs (probability-distribution-valued payoffs) showing that such uncertainty can be incorporated in the game-theoretic model by allowing payoffs to be random. In this paper, we combine our aforesaid works and we conclude that although uncertainties in cyber security risk assessment lead, on average, to different cyber security strategies, they do not play significant role into the final expected loss of the organization when using our model and methodology to derive this strategies. We show that our tool is capable of providing effective decision support. To the best of our knowledge this is the first paper that investigates how uncertainties on various parameters affect cyber security investments.",
      "publication_date": "2017-12-16T02:05:44+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.GT"
      ],
      "arxiv_id": "1712.05893v1"
    },
    {
      "title": "Fortify Your Defenses: Strategic Budget Allocation to Enhance Power Grid   Cybersecurity",
      "authors": [
        "Rounak Meyur",
        "Sumit Purohit",
        "Braden K. Webb"
      ],
      "abstract": "The abundance of cyber-physical components in modern day power grid with their diverse hardware and software vulnerabilities has made it difficult to protect them from advanced persistent threats (APTs). An attack graph depicting the propagation of potential cyber-attack sequences from the initial access point to the end objective is vital to identify critical weaknesses of any cyber-physical system. A cyber security personnel can accordingly plan preventive mitigation measures for the identified weaknesses addressing the cyber-attack sequences. However, limitations on available cybersecurity budget restrict the choice of mitigation measures. We address this aspect through our framework, which solves the following problem: given potential cyber-attack sequences for a cyber-physical component in the power grid, find the optimal manner to allocate an available budget to implement necessary preventive mitigation measures. We formulate the problem as a mixed integer linear program (MILP) to identify the optimal budget partition and set of mitigation measures which minimize the vulnerability of cyber-physical components to potential attack sequences. We assume that the allocation of budget affects the efficacy of the mitigation measures. We show how altering the budget allocation for tasks such as asset management, cybersecurity infrastructure improvement, incident response planning and employee training affects the choice of the optimal set of preventive mitigation measures and modifies the associated cybersecurity risk. The proposed framework can be used by cyber policymakers and system owners to allocate optimal budgets for various tasks required to improve the overall security of a cyber-physical system.",
      "publication_date": "2023-12-20T23:01:35+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "2312.13476v1"
    },
    {
      "title": "Contrasting the optimal resource allocation to cybersecurity and cyber   insurance using prospect theory versus expected utility theory",
      "authors": [
        "Chaitanya Joshi",
        "Jinming Yang",
        "Sergeja Slapnicar",
        "Ryan K L Ko"
      ],
      "abstract": "Protecting against cyber-threats is vital for every organization and can be done by investing in cybersecurity controls and purchasing cyber insurance. However, these are interlinked since insurance premiums could be reduced by investing more in cybersecurity controls. The expected utility theory and the prospect theory are two alternative theories explaining decision-making under risk and uncertainty, which can inform strategies for optimizing resource allocation. While the former is considered a rational approach, research has shown that most people make decisions consistent with the latter, including on insurance uptakes. We compare and contrast these two approaches to provide important insights into how the two approaches could lead to different optimal allocations resulting in differing risk exposure as well as financial costs. We introduce the concept of a risk curve and show that identifying the nature of the risk curve is a key step in deriving the optimal resource allocation.",
      "publication_date": "2024-11-28T00:59:48+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "econ.EM"
      ],
      "arxiv_id": "2411.18838v1"
    },
    {
      "title": "Optimizing Resource Allocation to Mitigate the Risk of Disruptive Events   in Homeland Security and Emergency Management",
      "authors": [
        "Parastoo Akbari",
        "Cameron A. MacKenzie"
      ],
      "abstract": "Homeland security in the United States faces a daunting task due to the multiple threats and hazards that can occur. Natural disasters, human-caused incidents such as terrorist attacks, and technological failures can result in significant damage, fatalities, injuries, and economic losses. The increasing frequency and severity of disruptive events in the United States highlight the urgent need for effectively allocating resources in homeland security and emergency preparedness. This article presents an optimization-based decision support model to help homeland security policymakers identify and select projects that best mitigate the risk of threats and hazards while satisfying a budget constraint. The model incorporates multiple hazards, probabilistic risk assessments, and multidimensional consequences and integrates historical data and publicly available sources to evaluate and select the most effective risk mitigation projects and optimize resource allocation across various disaster scenarios. We apply this model to the state of Iowa, considering 16 hazards, six types of consequences, and 52 mitigation projects. Our results demonstrate how different budget levels influence project selection, emphasizing cost-effective solutions that maximize risk reduction. Sensitivity analysis examines the robustness of project selection under varying effectiveness assumptions and consequence estimations. The findings offer critical insights for policymakers in homeland security and emergency management and provide a basis for more efficient resource allocation and improved disaster resilience.",
      "publication_date": "2025-04-03T14:49:15+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CY"
      ],
      "arxiv_id": "2504.02652v1"
    },
    {
      "title": "A Robust Stackelberg Game for Cyber-Security Investment in Networked   Control Systems",
      "authors": [
        "Pratishtha Shukla",
        "Lu An",
        "Aranya Chakrabortty",
        "Alexandra Duel-Hallen"
      ],
      "abstract": "We present a resource-planning game for cyber-security of networked control systems (NCS). The NCS is assumed to be operating in closed-loop using a linear state-feedback $\\mathcal{H}_2$ controller. A zero-sum, two-player Stackelberg game (SG) is developed between an attacker and a defender for this NCS. The attacker aims to disable communication of selected nodes and thereby render the feedback gain matrix to be sparse, leading to degradation of closed-loop performance, while the defender aims to prevent this loss by investing in the protection of targeted nodes. Both players trade their $\\mathcal{H}_2$-performance objectives for the costs of their actions. The standard backward induction method is modified to determine a cost-based Stackelberg equilibrium (CBSE) that saves the players' costs without degrading the control performance. We analyze the dependency of a CBSE on the relative budgets of the players as well as on the node \"importance\" order. Moreover, a robust-defense method is developed for the realistic case when the defender is not informed about the attacker's resources. The proposed algorithms are validated using examples from wide-area control of electric power systems. It is demonstrated that reliable and robust defense is feasible unless the defender's resources are severely limited relative to the attacker's resources. We also show that the proposed methods are robust to time-varying model uncertainties and thus are suitable for long-term security investment in realistic NCSs. Finally, we employ computationally efficient genetic algorithms (GA) to compute the optimal strategies of the attacker and the defender in realistic large power systems.",
      "publication_date": "2021-03-30T18:33:29+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "2103.16611v3"
    },
    {
      "title": "Robust Combinatorial Optimization with Locally Budgeted Uncertainty",
      "authors": [
        "Marc Goerigk",
        "Stefan Lendl"
      ],
      "abstract": "Budgeted uncertainty sets have been established as a major influence on uncertainty modeling for robust optimization problems. A drawback of such sets is that the budget constraint only restricts the global amount of cost increase that can be distributed by an adversary. Local restrictions, while being important for many applications, cannot be modeled this way.   We introduce new variant of budgeted uncertainty sets, called locally budgeted uncertainty. In this setting, the uncertain parameters become partitioned, such that a classic budgeted uncertainty set applies to each partition, called region.   In a theoretical analysis, we show that the robust counterpart of such problems for a constant number of regions remains solvable in polynomial time, if the underlying nominal problem can be solved in polynomial time as well. If the number of regions is unbounded, we show that the robust selection problem remains solvable in polynomial time, while also providing hardness results for other combinatorial problems.   In computational experiments using both random and real-world data, we show that using locally budgeted uncertainty sets can have considerable advantages over classic budgeted uncertainty sets.",
      "publication_date": "2020-08-27T12:15:01+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "2008.12076v1"
    },
    {
      "title": "Cyber Risk Assessment for Capital Management",
      "authors": [
        "Wing Fung Chong",
        "Runhuan Feng",
        "Hins Hu",
        "Linfeng Zhang"
      ],
      "abstract": "This paper introduces a two-pillar cyber risk management framework to address the pervasive challenges in managing cyber risk. The first pillar, cyber risk assessment, combines insurance frequency-severity models with cybersecurity cascade models to capture the unique nature of cyber risk. The second pillar, cyber capital management, facilitates informed allocation of capital for a balanced cyber risk management strategy, including cybersecurity investments, insurance coverage, and reserves. A case study, based on historical cyber incident data and realistic assumptions, demonstrates the necessity of comprehensive cost-benefit analysis for budget-constrained companies with competing objectives in cyber risk management. In addition, sensitivity analysis highlights the dependence of the optimal strategy on factors such as the price of cybersecurity controls and their effectiveness. The framework's implementation across a diverse range of companies yields general insights on cyber risk management.",
      "publication_date": "2022-05-17T15:25:23+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "q-fin.RM"
      ],
      "arxiv_id": "2205.08435v4"
    },
    {
      "title": "Integer linear programming supporting portfolio design",
      "authors": [
        "C. C. N. Kuhn",
        "G. Calbert",
        "I. Garanovich",
        "T. Weir"
      ],
      "abstract": "In large organisations and companies, making investment decisions is a complex and challenging task. In the Australian Department of Defence (Defence), the complexity is even higher because defence capabilities are public goods and do not have a financial return \\textit{per se}. In this work we mathematically define Defence's investment portfolio problem as a Set-Union Knapsack Problem (SUKP). We present a practical way to linearise the model as an Integer Linear Programming (ILP) problem. This linear model was developed as the optimisation engine of the New Investments to Risked Options (NITRO) portfolio selection tool developed by the Defence Science \\& Technology Group (DSTG) for Defence force design activities in 2021. The model is implemented in the Python package called PuLP which can call several linear solver's Application Programming Interface (API), such as GLPK, COIN CLP/CBC, IBM CPLEX, and Gurobi. After comparing the performance of several solvers, we chose Gurobi in the production server. The implementation of the new model and solver enables the rapid execution of exact solutions to the Defence investment portfolio problem.",
      "publication_date": "2023-03-25T05:22:24+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "2303.14364v1"
    },
    {
      "title": "A Stochastic-Robust Approach for Resilient Microgrid Investment Planning   Under Static and Transient Islanding Security Constraints",
      "authors": [
        "Agnes Marjorie Nakiganda",
        "Shahab Dehghan",
        "Uros Markovic",
        "Gabriela Hug",
        "Petros Aristidou"
      ],
      "abstract": "When planning the investment in Microgrids (MGs), usually static security constraints are included to ensure their resilience and ability to operate in islanded mode. However, unscheduled islanding events may trigger cascading disconnections of Distributed Energy Resources (DERs) inside the MG due to the transient response, leading to a partial or full loss of load. In this paper, a min-max-min, hybrid, stochastic-robust investment planning model is proposed to obtain a resilient MG considering both High-Impact-Low-Frequency (HILF) and Low-Impact-High-Frequency (LIHF) uncertainties. The HILF uncertainty pertains to the unscheduled islanding of the MG after a disastrous event, and the LIHF uncertainty relates to correlated loads and DER generation, characterized by a set of scenarios. The MG resilience under both types of uncertainty is ensured by incorporating static and transient islanding constraints into the proposed investment model. The inclusion of transient response constraints leads to a min-max-min problem with a non-linear dynamic frequency response model that cannot be solved directly by available optimization tools. Thus, in this paper, a three-stage solution approach is proposed to find the optimal investment plan. The performance of the proposed algorithm is tested on the CIGRE 18-node distribution network.",
      "publication_date": "2020-07-07T01:04:24+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "2007.03149v1"
    },
    {
      "title": "Comparing Decision Support Approaches for Cyber Security Investment",
      "authors": [
        "Andrew Fielder",
        "Emmanouil Panaousis",
        "Pasquale Malacaria",
        "Chris Hankin",
        "Fabrizio Smeraldi"
      ],
      "abstract": "When investing in cyber security resources, information security managers have to follow effective decision-making strategies. We refer to this as the cyber security investment challenge. In this paper, we consider three possible decision-support methodologies for security managers to tackle this challenge. We consider methods based on game theory, combinatorial optimisation and a hybrid of the two. Our modelling starts by building a framework where we can investigate the effectiveness of a cyber security control regarding the protection of different assets seen as targets in presence of commodity threats. In terms of game theory we consider a 2-person control game between the security manager who has to choose among different implementation levels of a cyber security control, and a commodity attacker who chooses among different targets to attack. The pure game theoretical methodology consists of a large game including all controls and all threats. In the hybrid methodology the game solutions of individual control-games along with their direct costs (e.g. financial) are combined with a knapsack algorithm to derive an optimal investment strategy. The combinatorial optimisation technique consists of a multi-objective multiple choice knapsack based strategy. We compare these approaches on a case study that was built on SANS top critical controls. The main achievements of this work is to highlight the weaknesses and strengths of different investment methodologies for cyber security, the benefit of their interaction, and the impact that indirect costs have on cyber security investment.",
      "publication_date": "2015-02-19T11:30:03+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.GT"
      ],
      "arxiv_id": "1502.05532v1"
    },
    {
      "title": "A Risk-Sensitive Portfolio Optimization Problem with Fixed Incomes   Securities",
      "authors": [
        "Mayank Goel",
        "K. Suresh Kumar"
      ],
      "abstract": "We discuss a class of risk-sensitive portfolio optimization problems. We consider the portfolio optimization model investigated by Nagai in 2003. The model by its nature can include fixed income securities as well in the portfolio. Under fairly general conditions, we prove the existence of optimal portfolio in both finite and infinite horizon problems.",
      "publication_date": "2007-11-17T05:46:12+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "q-fin.PM"
      ],
      "arxiv_id": "0711.2718v1"
    },
    {
      "title": "Minimal Investment Risk of Portfolio Optimization Problem with Budget   and Investment Concentration Constraints",
      "authors": [
        "Takashi Shinzato"
      ],
      "abstract": "In the present paper, the minimal investment risk for a portfolio optimization problem with imposed budget and investment concentration constraints is considered using replica analysis. Since the minimal investment risk is influenced by the investment concentration constraint (as well as the budget constraint), it is intuitive that the minimal investment risk for the problem with an investment concentration constraint be larger than that without the constraint (that is, with only the budget constraint). Moreover, a numerical experiment shows the effectiveness of our proposed analysis.",
      "publication_date": "2016-05-22T19:56:05+00:00",
      "doi": "10.1088/1742-5468/aa56a0",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "q-fin.PM"
      ],
      "arxiv_id": "1605.06845v1"
    },
    {
      "title": "Pricing and Investments in Internet Security: A Cyber-Insurance   Perspective",
      "authors": [
        "Ranjan Pal",
        "Leana Golubchik"
      ],
      "abstract": "Internet users such as individuals and organizations are subject to different types of epidemic risks such as worms, viruses, spams, and botnets. To reduce the probability of risk, an Internet user generally invests in traditional security mechanisms like anti-virus and anti-spam software, sometimes also known as self-defense mechanisms. However, such software does not completely eliminate risk. Recent works have considered the problem of residual risk elimination by proposing the idea of cyber-insurance. In this regard, an important research problem is the analysis of optimal user self-defense investments and cyber-insurance contracts under the Internet environment. In this paper, we investigate two problems and their relationship: 1) analyzing optimal self-defense investments in the Internet, under optimal cyber-insurance coverage, where optimality is an insurer objective and 2) designing optimal cyber-insurance contracts for Internet users, where a contract is a (premium, coverage) pair.",
      "publication_date": "2011-03-08T15:05:35+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "1103.1552v1"
    },
    {
      "title": "Efficient Traffic Classification using HW-NAS: Advanced Analysis and   Optimization for Cybersecurity on Resource-Constrained Devices",
      "authors": [
        "Adel Chehade",
        "Edoardo Ragusa",
        "Paolo Gastaldo",
        "Rodolfo Zunino"
      ],
      "abstract": "This paper presents a hardware-efficient deep neural network (DNN), optimized through hardware-aware neural architecture search (HW-NAS); the DNN supports the classification of session-level encrypted traffic on resource-constrained Internet of Things (IoT) and edge devices. Thanks to HW-NAS, a 1D convolutional neural network (CNN) is tailored on the ISCX VPN-nonVPN dataset to meet strict memory and computational limits while achieving robust performance. The optimized model attains an accuracy of 96.59% with just 88.26K parameters, 10.08M FLOPs, and a maximum tensor size of 20.12K. Compared to state-of-the-art models, it achieves reductions of up to 444-fold, 312-fold, and 15.6-fold in these metrics, respectively, significantly minimizing memory footprint and runtime requirements. The model also demonstrates versatility in classification tasks, achieving accuracies of up to 99.64% in VPN differentiation, VPN-type classification, broader traffic categories, and application identification. In addition, an in-depth approach to header-level preprocessing strategies confirms that the optimized model can provide notable performances across a wide range of configurations, even in scenarios with stricter privacy considerations. Likewise, a reduction in the length of sessions of up to 75% yields significant improvements in efficiency, while maintaining high accuracy with only a negligible drop of 1-2%. However, the importance of careful preprocessing and session length selection in the classification of raw traffic data is still present, as improper settings or aggressive reductions can bring about a 7% reduction in overall accuracy. Those results highlight the method's effectiveness in enforcing cybersecurity for IoT networks, by providing scalable, efficient solutions for the real-time analysis of encrypted traffic within strict hardware limitations.",
      "publication_date": "2025-06-12T21:37:45+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.NI"
      ],
      "arxiv_id": "2506.11319v1"
    },
    {
      "title": "Portfolio problems with two levels decision-makers: Optimal portfolio   selection with pricing decisions on transaction costs. Extended version and   complete risk profiles analysis",
      "authors": [
        "Marina Leal",
        "Diego Ponce",
        "Justo Puerto"
      ],
      "abstract": "This paper presents novel bilevel leader-follower portfolio selection problems in which the financial intermediary becomes a decision-maker. This financial intermediary decides on the unit transaction costs for investing in some securities, maximizing its benefits, and the investor chooses his optimal portfolio, minimizing risk and ensuring a given expected return. Hence, transaction costs become decision variables in the portfolio problem, and two levels of decision-makers are incorporated: the financial intermediary and the investor. These situations give rise to general Nonlinear Programming formulations in both levels of the decision process. We present different bilevel versions of the problem: financial intermediary-leader, investor-leader, and social welfare; besides, their properties are analyzed. Moreover, we develop Mixed Integer Linear Programming formulations for some of the proposed problems and effective algorithms for some others. Finally, we report on some computational experiments performed on data taken from the Dow Jones Industrial Average, and analyze and compare the results obtained by the different models.",
      "publication_date": "2018-04-11T19:11:09+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "1804.04174v2"
    },
    {
      "title": "A Bonus-Malus Framework for Cyber Risk Insurance and Optimal   Cybersecurity Provisioning",
      "authors": [
        "Qikun Xiang",
        "Ariel Neufeld",
        "Gareth W. Peters",
        "Ido Nevat",
        "Anwitaman Datta"
      ],
      "abstract": "The cyber risk insurance market is at a nascent stage of its development, even as the magnitude of cyber losses is significant and the rate of cyber loss events is increasing. Existing cyber risk insurance products as well as academic studies have been focusing on classifying cyber loss events and developing models of these events, but little attention has been paid to proposing insurance risk transfer strategies that incentivise mitigation of cyber loss through adjusting the premium of the risk transfer product. To address this important gap, we develop a Bonus-Malus model for cyber risk insurance. Specifically, we propose a mathematical model of cyber risk insurance and cybersecurity provisioning supported with an efficient numerical algorithm based on dynamic programming. Through a numerical experiment, we demonstrate how a properly designed cyber risk insurance contract with a Bonus-Malus system can resolve the issue of moral hazard and benefit the insurer.",
      "publication_date": "2021-02-10T16:57:13+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "2102.05568v4"
    },
    {
      "title": "Constrained Risk Budgeting Portfolios: Theory, Algorithms, Applications   & Puzzles",
      "authors": [
        "Jean-Charles Richard",
        "Thierry Roncalli"
      ],
      "abstract": "This article develops the theory of risk budgeting portfolios, when we would like to impose weight constraints. It appears that the mathematical problem is more complex than the traditional risk budgeting problem. The formulation of the optimization program is particularly critical in order to determine the right risk budgeting portfolio. We also show that numerical solutions can be found using methods that are used in large-scale machine learning problems. Indeed, we develop an algorithm that mixes the method of cyclical coordinate descent (CCD), alternating direction method of multipliers (ADMM), proximal operators and Dykstra's algorithm. This theoretical body is then applied to some investment problems. In particular, we show how to dynamically control the turnover of a risk parity portfolio and how to build smart beta portfolios based on the ERC approach by improving the liquidity of the portfolio or reducing the small cap bias. Finally, we highlight the importance of the homogeneity property of risk measures and discuss the related scaling puzzle.",
      "publication_date": "2019-02-15T07:41:14+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "q-fin.PM"
      ],
      "arxiv_id": "1902.05710v1"
    },
    {
      "title": "Dynamic Portfolio Optimization with a Defaultable Security and Regime   Switching",
      "authors": [
        "Agostino Capponi",
        "Jose E. Figueroa-Lopez"
      ],
      "abstract": "We consider a portfolio optimization problem in a defaultable market with finitely-many economical regimes, where the investor can dynamically allocate her wealth among a defaultable bond, a stock, and a money market account. The market coefficients are assumed to depend on the market regime in place, which is modeled by a finite state continuous time Markov process. We rigorously deduce the dynamics of the defaultable bond price process in terms of a Markov modulated stochastic differential equation. Then, by separating the utility maximization problem into the pre-default and post-default scenarios, we deduce two coupled Hamilton-Jacobi-Bellman equations for the post and pre-default optimal value functions and show a novel verification theorem for their solutions. We obtain explicit optimal investment strategies and value functions for an investor with logarithmic utility. We finish with an economic analysis in the case of a market with two regimes and homogenous transition rates, and show the impact of the default intensities and loss rates on the optimal strategies and value functions.",
      "publication_date": "2011-04-30T03:05:32+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "q-fin.PM"
      ],
      "arxiv_id": "1105.0042v2"
    },
    {
      "title": "LENS-XAI: Redefining Lightweight and Explainable Network Security   through Knowledge Distillation and Variational Autoencoders for Scalable   Intrusion Detection in Cybersecurity",
      "authors": [
        "Muhammet Anil Yagiz",
        "Polat Goktas"
      ],
      "abstract": "The rapid proliferation of Industrial Internet of Things (IIoT) systems necessitates advanced, interpretable, and scalable intrusion detection systems (IDS) to combat emerging cyber threats. Traditional IDS face challenges such as high computational demands, limited explainability, and inflexibility against evolving attack patterns. To address these limitations, this study introduces the Lightweight Explainable Network Security framework (LENS-XAI), which combines robust intrusion detection with enhanced interpretability and scalability. LENS-XAI integrates knowledge distillation, variational autoencoder models, and attribution-based explainability techniques to achieve high detection accuracy and transparency in decision-making. By leveraging a training set comprising 10% of the available data, the framework optimizes computational efficiency without sacrificing performance. Experimental evaluation on four benchmark datasets: Edge-IIoTset, UKM-IDS20, CTU-13, and NSL-KDD, demonstrates the framework's superior performance, achieving detection accuracies of 95.34%, 99.92%, 98.42%, and 99.34%, respectively. Additionally, the framework excels in reducing false positives and adapting to complex attack scenarios, outperforming existing state-of-the-art methods. Key strengths of LENS-XAI include its lightweight design, suitable for resource-constrained environments, and its scalability across diverse IIoT and cybersecurity contexts. Moreover, the explainability module enhances trust and transparency, critical for practical deployment in dynamic and sensitive applications. This research contributes significantly to advancing IDS by addressing computational efficiency, feature interpretability, and real-world applicability. Future work could focus on extending the framework to ensemble AI systems for distributed environments, further enhancing its robustness and adaptability.",
      "publication_date": "2025-01-01T10:00:49+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "2501.00790v2"
    },
    {
      "title": "Hierarchical Constrained Stochastic Shortest Path Planning via Cost   Budget Allocation",
      "authors": [
        "Sungkweon Hong",
        "Brian C. Williams"
      ],
      "abstract": "Stochastic sequential decision making often requires hierarchical structure in the problem where each high-level action should be further planned with primitive states and actions. In addition, many real-world applications require a plan that satisfies constraints on the secondary costs such as risk measure or fuel consumption. In this paper, we propose a hierarchical constrained stochastic shortest path problem (HC-SSP) that meets those two crucial requirements in a single framework. Although HC-SSP provides a useful framework to model such planning requirements in many real-world applications, the resulting problem has high complexity and makes it difficult to find an optimal solution fast which prevents user from applying it to real-time and risk-sensitive applications. To address this problem, we present an algorithm that iteratively allocates cost budget to lower level planning problems based on branch-and-bound scheme to find a feasible solution fast and incrementally update the incumbent solution. We demonstrate the proposed algorithm in an evacuation scenario and prove the advantage over a state-of-the-art mathematical programming based approach.",
      "publication_date": "2022-05-11T01:25:38+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.AI"
      ],
      "arxiv_id": "2205.05228v1"
    },
    {
      "title": "A stochastic Gordon-Loeb model for optimal cybersecurity investment   under clustered attacks",
      "authors": [
        "Giorgia Callegaro",
        "Claudio Fontana",
        "Caroline Hillairet",
        "Beatrice Ongarato"
      ],
      "abstract": "We develop a continuous-time stochastic model for optimal cybersecurity investment under the threat of cyberattacks. The arrival of attacks is modeled using a Hawkes process, capturing the empirically relevant feature of clustering in cyberattacks. Extending the Gordon-Loeb model, each attack may result in a breach, with breach probability depending on the system's vulnerability. We aim at determining the optimal cybersecurity investment to reduce vulnerability. The problem is cast as a two-dimensional Markovian stochastic optimal control problem and solved using dynamic programming methods. Numerical results illustrate how accounting for attack clustering leads to more responsive and effective investment policies, offering significant improvements over static and Poisson-based benchmark strategies. Our findings underscore the value of incorporating realistic threat dynamics into cybersecurity risk management.",
      "publication_date": "2025-05-02T12:15:44+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "q-fin.RM"
      ],
      "arxiv_id": "2505.01221v1"
    },
    {
      "title": "Robust Combinatorial Optimization Problems Under Budgeted Interdiction   Uncertainty",
      "authors": [
        "Marc Goerigk",
        "Mohammad Khosravi"
      ],
      "abstract": "In robust combinatorial optimization, we would like to find a solution that performs well under all realizations of an uncertainty set of possible parameter values. How we model this uncertainty set has a decisive influence on the complexity of the corresponding robust problem. For this reason, budgeted uncertainty sets are often studied, as they enable us to decompose the robust problem into easier subproblems. We propose a variant of discrete budgeted uncertainty for cardinality-based constraints or objectives, where a weight vector is applied to the budget constraint. We show that while the adversarial problem can be solved in linear time, the robust problem becomes NP-hard and not approximable. We discuss different possibilities to model the robust problem and show experimentally that despite the hardness result, some models scale relatively well in the problem size.",
      "publication_date": "2023-07-17T14:37:24+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "2307.08525v2"
    },
    {
      "title": "Compact Securities Markets for Pareto Optimal Reallocation of Risk",
      "authors": [
        "David M. Pennock",
        "Michael P. Wellman"
      ],
      "abstract": "The emph{securities market} is the fundamental theoretical framework in economics and finance for resource allocation under uncertainty. Securities serve both to reallocate risk and to disseminate probabilistic information. emph{Complete} securities markets - which contain one security for every possible state of nature - support Pareto optimal allocations of risk. Complete markets suffer from the same exponential dependence on the number of underlying events as do joint probability distributions. We examine whether markets can be structured and \"compacted\" in the same manner as Bayesian network representations of joint distributions. We show that, if all agents' risk-neutral independencies agree with the independencies encoded in the market structure, then the market is emph{operationally complete}: risk is still Pareto optimally allocated, yet the number of securities can be exponentially smaller. For collections of agents of a certain type, agreement on Markov independencies is sufficient to admit compact and operationally complete markets.",
      "publication_date": "2013-01-16T15:52:13+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.GT"
      ],
      "arxiv_id": "1301.3886v1"
    },
    {
      "title": "Enhancing Physical Layer Security in Dual-Hop Multiuser Transmission",
      "authors": [
        "Waqas Aman",
        "Guftaar Ahmad Sardar Sidhu",
        "Tayyaba Jabeen",
        "Feifei Gao",
        "Shi Jin"
      ],
      "abstract": "In this paper, we consider the Physical Layer Security(PLS) problem in orthogonal frequency division multiple access (OFDMA) based dual-hop system which consists of multiple users, multiple amplify and forward relays, and an eavesdropper. The aim is to enhance PLS of the entire system by maximizing sum secrecy rate of secret users through optimal resource allocation under various practical constraints. Specifically, the sub-carrier allocation to different users, the relay assignments, and the power loading over different sub-carriers at transmitting nodes are optimized. The joint optimization problem is modeled as a mixed binary integer programming problem subject to exclusive sub-carrier allocation and separate power budget constraints at each node. A joint optimization solution is obtained through Lagrangian dual decomposition where KKT conditions are exploited to find the optimal power allocation at base station. Further, to reduce the complexity, a sub-optimal scheme is presented where the optimal power allocation is derived under fixed sub-carrier-relay assignment. Simulation results are also provided to validate the performance of proposed schemes.",
      "publication_date": "2017-03-19T18:08:51+00:00",
      "doi": "10.1109/WCNC.2016.7564989",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.IT"
      ],
      "arxiv_id": "1703.06483v1"
    },
    {
      "title": "Robust portfolio optimization with multi-factor stochastic volatility",
      "authors": [
        "Ben-Zhang Yang",
        "Xiaoping Lu",
        "Guiyuan Ma",
        "Song-Ping Zhu"
      ],
      "abstract": "This paper studies a robust portfolio optimization problem under the multi-factor volatility model introduced by Christoffersen et al. (2009). The optimal strategy is derived analytically under the worst-case scenario with or without derivative trading. To illustrate the effects of ambiguity, we compare our optimal robust strategy with some strategies that ignore the information of uncertainty, and provide the corresponding welfare analysis. The effects of derivative trading to the optimal portfolio selection are also discussed by considering alternative strategies. Our study is further extended to the cases with jump risks in asset price and correlated volatility factors, respectively. Numerical experiments are provided to demonstrate the behavior of the optimal portfolio and utility loss.",
      "publication_date": "2019-10-15T15:33:07+00:00",
      "doi": "10.1007/s10957-020-01687-w",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "q-fin.MF"
      ],
      "arxiv_id": "1910.06872v3"
    },
    {
      "title": "Optimizing Investments in Cyber Hygiene for Protecting Healthcare Users",
      "authors": [
        "Sakshyam Panda",
        "Emmanouil Panaousis",
        "George Loukas",
        "Christos Laoudias"
      ],
      "abstract": "Cyber hygiene measures are often recommended for strengthening an organization's security posture, especially for protecting against social engineering attacks that target the human element. However, the related recommendations are typically the same for all organizations and their employees, regardless of the nature and the level of risk for different groups of users. Building upon an existing cybersecurity investment model, this paper presents a tool for optimal selection of cyber hygiene safeguards, which we refer as the Optimal Safeguards Tool. The model combines game theory and combinatorial optimization taking into account the probability of each user group to being attacked, the value of assets accessible by each group, and the efficacy of each control for a particular group. The model considers indirect cost as the time employees could require for learning and training against an implemented control. Utilizing a game-theoretic framework to support the Knapsack optimization problem permits us to optimally select safeguards' application levels minimizing the aggregated expected damage within a security investment budget. We evaluate OST in a healthcare domain use case. The Critical Internet Security Control group 17 for implementing security awareness and training programs for employees belonging to the ICT, clinical and administration personnel of a hospital. We compare the strategies implemented by OST against alternative common-sense defending approaches for three different types of attackers: Nash, Weighted and Opportunistic. Nash defending strategies are consistently better than the competing strategies for all attacker types with a minor exception where the Nash defending strategy performs at least as good as other common-sense approaches.",
      "publication_date": "2020-01-11T18:47:50+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "2001.03782v1"
    },
    {
      "title": "Robustifying Conditional Portfolio Decisions via Optimal Transport",
      "authors": [
        "Viet Anh Nguyen",
        "Fan Zhang",
        "Shanshan Wang",
        "Jose Blanchet",
        "Erick Delage",
        "Yinyu Ye"
      ],
      "abstract": "We propose a data-driven portfolio selection model that integrates side information, conditional estimation and robustness using the framework of distributionally robust optimization. Conditioning on the observed side information, the portfolio manager solves an allocation problem that minimizes the worst-case conditional risk-return trade-off, subject to all possible perturbations of the covariate-return probability distribution in an optimal transport ambiguity set. Despite the non-linearity of the objective function in the probability measure, we show that the distributionally robust portfolio allocation with side information problem can be reformulated as a finite-dimensional optimization problem. If portfolio decisions are made based on either the mean-variance or the mean-Conditional Value-at-Risk criterion, the resulting reformulation can be further simplified to second-order or semi-definite cone programs. Empirical studies in the US equity market demonstrate the advantage of our integrative framework against other benchmarks.",
      "publication_date": "2021-03-30T15:56:03+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "q-fin.PM"
      ],
      "arxiv_id": "2103.16451v3"
    },
    {
      "title": "A Comprehensive Survey of Linear, Integer, and Mixed-Integer Programming   Approaches for Optimizing Resource Allocation in 5G and Beyond Networks",
      "authors": [
        "Naveed Ejaz",
        "Salimur Choudhury"
      ],
      "abstract": "The introduction of 5G networks has significantly advanced communication technology, offering faster speeds, lower latency, and greater capacity. This progress sets the stage for Beyond 5G (B5G) networks, which present new complexity and performance requirements challenges. Linear Programming (LP), Integer Linear Programming (ILP), and Mixed-Integer Linear Programming (MILP) models have been widely used to model the optimization of resource allocation problems in networks. This paper reviews 103 studies on resource allocation strategies in 5G and B5G, focusing specifically on optimization problems modelled as LP, ILP, and MILP. The selected studies are categorized based on network architectures, types of resource allocation problems, and specific objective functions and constraints. The review also discusses solution methods for NP-hard ILP and MILP problems by categorizing the solution methods into different categories. Additionally, emerging trends, such as integrating AI and machine learning with optimization models, are explored, suggesting promising future research directions in network optimization. The paper concludes that LP, ILP, and MILP models have been widely adopted across various network architectures, resource types, objective functions, and constraints and remain critical to optimizing next-generation networks.",
      "publication_date": "2025-02-21T16:52:40+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.NI"
      ],
      "arxiv_id": "2502.15585v1"
    },
    {
      "title": "On Cost-Sensitive Distributionally Robust Log-Optimal Portfolio",
      "authors": [
        "Chung-Han Hsieh",
        "Xiao-Rou Yu"
      ],
      "abstract": "This paper addresses a novel \\emph{cost-sensitive} distributionally robust log-optimal portfolio problem, where the investor faces \\emph{ambiguous} return distributions, and a general convex transaction cost model is incorporated. The uncertainty in the return distribution is quantified using the \\emph{Wasserstein} metric, which captures distributional ambiguity. We establish conditions that ensure robustly survivable trades for all distributions in the Wasserstein ball under convex transaction costs. By leveraging duality theory, we approximate the infinite-dimensional distributionally robust optimization problem with a finite convex program, enabling computational tractability for mid-sized portfolios. Empirical studies using S\\&P 500 data validate our theoretical framework: without transaction costs, the optimal portfolio converges to an equal-weighted allocation, while with transaction costs, the portfolio shifts slightly towards the risk-free asset, reflecting the trade-off between cost considerations and optimal allocation.",
      "publication_date": "2024-10-31T00:56:47+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "2410.23536v1"
    },
    {
      "title": "GMA: A Pareto Optimal Distributed Resource-Allocation Algorithm",
      "authors": [
        "Giacomo Giuliari",
        "Marc Wyss",
        "Markus Legner",
        "Adrian Perrig"
      ],
      "abstract": "To address the rising demand for strong packet delivery guarantees in networking, we study a novel way to perform graph resource allocation. We first introduce allocation graphs, in which nodes can independently set local resource limits based on physical constraints or policy decisions. In this scenario we formalize the distributed path-allocation (PAdist) problem, which consists in allocating resources to paths considering only local on-path information -- importantly, not knowing which other paths could have an allocation -- while at the same time achieving the global property of never exceeding available resources.   Our core contribution, the global myopic allocation (GMA) algorithm, is a solution to this problem. We prove that GMA can compute unconditional allocations for all paths on a graph, while never over-allocating resources. Further, we prove that GMA is Pareto optimal with respect to the allocation size, and it has linear complexity in the input size. Finally, we show with simulations that this theoretical result could be indeed applied to practical scenarios, as the resulting path allocations are large enough to fit the requirements of practically relevant applications.",
      "publication_date": "2021-02-20T11:15:24+00:00",
      "doi": "10.1007/978-3-030-79527-6_14",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.NI"
      ],
      "arxiv_id": "2102.10314v2"
    },
    {
      "title": "Constrained Max Drawdown: a Fast and Robust Portfolio Optimization   Approach",
      "authors": [
        "Albert Dorador"
      ],
      "abstract": "We propose an alternative linearization to the classical Markowitz quadratic portfolio optimization model, based on maximum drawdown. This model, which minimizes maximum portfolio drawdown, is particularly appealing during times of financial distress, like during the COVID-19 pandemic. In addition, we will present a Mixed-Integer Linear Programming variation of our new model that, based on our out-of-sample results and sensitivity analysis, delivers a more profitable and robust solution with a 200 times faster solving time compared to the standard Markowitz quadratic formulation.",
      "publication_date": "2024-01-05T01:52:39+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "q-fin.PM"
      ],
      "arxiv_id": "2401.02601v1"
    },
    {
      "title": "Robust Deterministic Policies for Markov Decision Processes under   Budgeted Uncertainty",
      "authors": [
        "Fei Wu",
        "Erik Demeulemeester",
        "Jannik Matuschke"
      ],
      "abstract": "This paper studies the computation of robust deterministic policies for Markov Decision Processes (MDPs) in the Lightning Does Not Strike Twice (LDST) model of Mannor, Mebel and Xu (ICML '12). In this model, designed to provide robustness in the face of uncertain input data while not being overly conservative, transition probabilities and rewards are uncertain and the uncertainty set is constrained by a budget that limits the number of states whose parameters can deviate from their nominal values.   Mannor et al. (ICML '12) showed that optimal randomized policies for MDPs in the LDST regime can be efficiently computed when only the rewards are affected by uncertainty. In contrast to these findings, we observe that the computation of optimal deterministic policies is $N\\!P$-hard even when only a single terminal reward may deviate from its nominal value and the MDP consists of $2$ time periods. For this hard special case, we then derive a constant-factor approximation algorithm by combining two relaxations based on the Knapsack Cover and Generalized Assignment problem, respectively. For the general problem with possibly a large number of deviations and a longer time horizon, we derive strong inapproximability results for computing robust deterministic policies as well as $\\Sigma_2^p$-hardness, indicating that the general problem does not even admit a compact mixed integer programming formulation.",
      "publication_date": "2024-12-17T13:04:19+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "2412.12879v1"
    },
    {
      "title": "Risk management in multi-objective portfolio optimization under   uncertainty",
      "authors": [
        "Yannick Becker",
        "Pascal Halffmann",
        "Anita Schbel"
      ],
      "abstract": "In portfolio optimization, decision makers face difficulties from uncertainties inherent in real-world scenarios. These uncertainties significantly influence portfolio outcomes in both classical and multi-objective Markowitz models. To address these challenges, our research explores the power of robust multi-objective optimization. Since portfolio managers frequently measure their solutions against benchmarks, we enhance the multi-objective min-regret robustness concept by incorporating these benchmark comparisons.   This approach bridges the gap between theoretical models and real-world investment scenarios, offering portfolio managers more reliable and adaptable strategies for navigating market uncertainties. Our framework provides a more nuanced and practical approach to portfolio optimization under real-world conditions.",
      "publication_date": "2024-07-29T12:17:11+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "q-fin.PM"
      ],
      "arxiv_id": "2407.19936v1"
    },
    {
      "title": "Pareto Adaptive Robust Optimality via a Fourier-Motzkin Elimination Lens",
      "authors": [
        "Dimitris Bertsimas",
        "Stefan ten Eikelder",
        "Dick den Hertog",
        "Nikolaos Trichakis"
      ],
      "abstract": "We formalize the concept of Pareto Adaptive Robust Optimality (PARO) for linear Adaptive Robust Optimization (ARO) problems. A worst-case optimal solution pair of here-and-now decisions and wait-and-see decisions is PARO if it cannot be Pareto dominated by another solution, i.e., there does not exist another such pair that performs at least as good in all scenarios in the uncertainty set and strictly better in at least one scenario. We argue that, unlike PARO, extant solution approaches -- including those that adopt Pareto Robust Optimality from static robust optimization -- could fail in ARO and yield solutions that can be Pareto dominated. The latter could lead to inefficiencies and suboptimal performance in practice. We prove the existence of PARO solutions, and present particular approaches for finding and approximating such solutions. We present numerical results for a facility location problem that demonstrate the practical value of PARO solutions. Our analysis of PARO relies on an application of Fourier-Motzkin Elimination as a proof technique. We demonstrate how this technique can be valuable in the analysis of ARO problems, besides PARO. In particular, we employ it to devise more concise and more insightful proofs of known results on (worst-case) optimality of decision rule structures.",
      "publication_date": "2020-12-08T13:30:34+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "2012.04419v3"
    },
    {
      "title": "A Quantal Response Analysis of Defender-Attacker Sequential Security   Games",
      "authors": [
        "Md Reya Shad Azim",
        "Mustafa Abdallah"
      ],
      "abstract": "We explore a scenario involving two sites and a sequential game between a defender and an attacker, where the defender is responsible for securing the sites while the attacker aims to attack them. Each site holds a loss value for the defender when compromised, along with a probability of successful attack. The defender can reduce these probabilities through security investments at each site. The attacker's objective is to target the site that maximizes the expected loss for the defender, taking into account the defender's security investments. While previous studies have examined security investments in such scenarios, our work investigates the impact of bounded rationality exhibited by the defender, as identified in behavioral economics. Specifically, we consider quantal behavioral bias, where humans make errors in selecting efficient (pure) strategies. We demonstrate the existence of a quantal response equilibrium in our sequential game and analyze how this bias affects the defender's choice of optimal security investments. Additionally, we quantify the inefficiency of equilibrium investments under quantal decision-making compared to an optimal solution devoid of behavioral biases. We provide numerical simulations to validate our main findings.",
      "publication_date": "2024-08-02T00:40:48+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.GT"
      ],
      "arxiv_id": "2408.00964v1"
    },
    {
      "title": "Replica Analysis for the Duality of the Portfolio Optimization Problem",
      "authors": [
        "Takashi Shinzato"
      ],
      "abstract": "In the present paper, the primal-dual problem consisting of the investment risk minimization problem and the expected return maximization problem in the mean-variance model is discussed using replica analysis. As a natural extension of the investment risk minimization problem under only a budget constraint that we analyzed in a previous study, we herein consider a primal-dual problem in which the investment risk minimization problem with budget and expected return constraints is regarded as the primal problem, and the expected return maximization problem with budget and investment risk constraints is regarded as the dual problem. With respect to these optimal problems, we analyze a quenched disordered system involving both of these optimization problems using the approach developed in statistical mechanical informatics, and confirm that both optimal portfolios can possess the primal-dual structure. Finally, the results of numerical simulations are shown to validate the effectiveness of the proposed method.",
      "publication_date": "2016-09-18T12:09:28+00:00",
      "doi": "10.1103/PhysRevE.94.052307",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "q-fin.PM"
      ],
      "arxiv_id": "1609.05475v1"
    },
    {
      "title": "A Convex Stochastic Optimization Problem Arising from Portfolio   Selection",
      "authors": [
        "Hanqing Jin",
        "Zuo Quan Xu",
        "Xun Yu Zhou"
      ],
      "abstract": "A continuous-time financial portfolio selection model with expected utility maximization typically boils down to solving a (static) convex stochastic optimization problem in terms of the terminal wealth, with a budget constraint. In literature the latter is solved by assuming {\\it a priori} that the problem is well-posed (i.e., the supremum value is finite) and a Lagrange multiplier exists (and as a consequence the optimal solution is attainable). In this paper it is first shown, via various counter-examples, neither of these two assumptions needs to hold, and an optimal solution does not necessarily exist. These anomalies in turn have important interpretations in and impacts on the portfolio selection modeling and solutions. Relations among the non-existence of the Lagrange multiplier, the ill-posedness of the problem, and the non-attainability of an optimal solution are then investigated. Finally, explicit and easily verifiable conditions are derived which lead to finding the unique optimal solution.",
      "publication_date": "2007-09-27T18:21:07+00:00",
      "doi": "10.1111/j.1467-9965.2007.00327.x",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "q-fin.PM"
      ],
      "arxiv_id": "0709.4467v1"
    },
    {
      "title": "Robust Binary Linear Programming Under Implementation Uncertainty",
      "authors": [
        "Jose E. Ramirez-Calderon",
        "V. Jorge Leon"
      ],
      "abstract": "This paper studies binary linear programming problems in the presence of uncertainties that may cause solution values to change during implementation. This type of uncertainty, termed implementation uncertainty, is modeled explicitly affecting the decision variables rather than model parameters. The binary nature of the decision variables invalidates the use of the existing models for this type of uncertainty. The robust solutions obtained are optimal for a worst-case min-max objective and allow a controlled degree of infeasibility with respect to the associated deterministic problem. Structural properties are used to reformulate the problem as a mixed-integer linear binary program. The degree of solution conservatism is controlled by combining both constraint relaxation and cardinality-constrained parameters. Solutions for optimization problems under implementation uncertainty consist of a set of robust solutions; the selection of solutions from this possibly large set is formulated as an optimization problem over the robust set. Results from an experimental study in the context of the knapsack problem suggest the methodology yields solutions that perform well in terms of objective value and feasibility. Furthermore, the selection approach can identify robust solutions that possess desirable implementation characteristics.",
      "publication_date": "2021-09-28T02:21:44+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "2109.13436v1"
    },
    {
      "title": "A Novel Cyber-Insurance for Internet Security",
      "authors": [
        "Ranjan Pal",
        "Leana Golubchik",
        "Konstantinos Psounis"
      ],
      "abstract": "Internet users such as individuals and organizations are subject to different types of epidemic risks such as worms, viruses, and botnets. To reduce the probability of risk, an Internet user generally invests in self-defense mechanisms like antivirus and antispam software. However, such software does not completely eliminate risk. Recent works have considered the problem of residual risk elimination by proposing the idea of cyber-insurance. In reality, an Internet user faces risks due to security attacks as well as risks due to non-security related failures (e.g., reliability faults in the form of hardware crash, buffer overflow, etc.) . These risk types are often indistinguishable by a naive user. However, a cyber-insurance agency would most likely insure risks only due to security attacks. In this case, it becomes a challenge for an Internet user to choose the right type of cyber-insurance contract as standard optimal contracts, i.e., contracts under security attacks only, might prove to be sub-optimal for himself. In this paper, we address the problem of analyzing cyber-insurance solutions when a user faces risks due to both, security as well as non-security related failures. We propose \\emph{Aegis}, a novel cyber-insurance model in which the user accepts a fraction \\emph{(strictly positive)} of loss recovery on himself and transfers rest of the loss recovery on the cyber-insurance agency. We mathematically show that given an option, Internet users would prefer Aegis contracts to traditional cyber-insurance contracts, under all premium types. This result firmly establishes the non-existence of traditional cyber-insurance markets when Aegis contracts are offered to users.",
      "publication_date": "2011-07-24T18:46:54+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.CR"
      ],
      "arxiv_id": "1107.4785v1"
    },
    {
      "title": "Pareto Optima of Multicriteria Integer Linear Programs",
      "authors": [
        "Jess A. De Loera",
        "Raymond Hemmecke",
        "Matthias Kppe"
      ],
      "abstract": "We settle the computational complexity of fundamental questions related to multicriteria integer linear programs, when the dimensions of the strategy space and of the outcome space are considered fixed constants. In particular we construct:   1. polynomial-time algorithms to exactly determine the number of Pareto optima and Pareto strategies;   2. a polynomial-space polynomial-delay prescribed-order enumeration algorithm for arbitrary projections of the Pareto set;   3. an algorithm to minimize the distance of a Pareto optimum from a prescribed comparison point with respect to arbitrary polyhedral norms;   4. a fully polynomial-time approximation scheme for the problem of minimizing the distance of a Pareto optimum from a prescribed comparison point with respect to the Euclidean norm.",
      "publication_date": "2007-07-10T03:52:59+00:00",
      "doi": "10.1287/ijoc.1080.0277",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "0707.1362v1"
    },
    {
      "title": "PAC-Bayesian Treatment Allocation Under Budget Constraints",
      "authors": [
        "Daniel F. Pellatt"
      ],
      "abstract": "This paper considers the estimation of treatment assignment rules when the policy maker faces a general budget or resource constraint. Utilizing the PAC-Bayesian framework, we propose new treatment assignment rules that allow for flexible notions of treatment outcome, treatment cost, and a budget constraint. For example, the constraint setting allows for cost-savings, when the costs of non-treatment exceed those of treatment for a subpopulation, to be factored into the budget. It also accommodates simpler settings, such as quantity constraints, and doesn't require outcome responses and costs to have the same unit of measurement. Importantly, the approach accounts for settings where budget or resource limitations may preclude treating all that can benefit, where costs may vary with individual characteristics, and where there may be uncertainty regarding the cost of treatment rules of interest. Despite the nomenclature, our theoretical analysis examines frequentist properties of the proposed rules. For stochastic rules that typically approach budget-penalized empirical welfare maximizing policies in larger samples, we derive non-asymptotic generalization bounds for the target population costs and sharp oracle-type inequalities that compare the rules' welfare regret to that of optimal policies in relevant budget categories. A closely related, non-stochastic, model aggregation treatment assignment rule is shown to inherit desirable attributes.",
      "publication_date": "2022-12-18T04:22:16+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "econ.EM"
      ],
      "arxiv_id": "2212.09007v2"
    },
    {
      "title": "Cardinality-constrained Distributionally Robust Portfolio Optimization",
      "authors": [
        "Ken Kobayashi",
        "Yuichi Takano",
        "Kazuhide Nakata"
      ],
      "abstract": "This paper studies a distributionally robust portfolio optimization model with a cardinality constraint for limiting the number of invested assets. We formulate this model as a mixed-integer semidefinite optimization (MISDO) problem by means of the moment-based ambiguity set of probability distributions of asset returns. To exactly solve large-scale problems, we propose a specialized cutting-plane algorithm that is based on bilevel optimization reformulation. We prove the finite convergence of the algorithm. We also apply a matrix completion technique to lower-level SDO problems to make their problem sizes much smaller. Numerical experiments demonstrate that our cutting-plane algorithm is significantly faster than the state-of-the-art MISDO solver SCIP-SDP. We also show that our portfolio optimization model can achieve good investment performance compared with the conventional robust optimization model based on the ellipsoidal uncertainty set.",
      "publication_date": "2021-12-23T10:45:23+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "2112.12454v2"
    },
    {
      "title": "Hierarchical Deep Reinforcement Learning Framework for Multi-Year Asset   Management Under Budget Constraints",
      "authors": [
        "Amir Fard",
        "Arnold X. -X. Yuan"
      ],
      "abstract": "Budget planning and maintenance optimization are crucial for infrastructure asset management, ensuring cost-effectiveness and sustainability. However, the complexity arising from combinatorial action spaces, diverse asset deterioration, stringent budget constraints, and environmental uncertainty significantly limits existing methods' scalability. This paper proposes a Hierarchical Deep Reinforcement Learning methodology specifically tailored to multi-year infrastructure planning. Our approach decomposes the problem into two hierarchical levels: a high-level Budget Planner allocating annual budgets within explicit feasibility bounds, and a low-level Maintenance Planner prioritizing assets within the allocated budget. By structurally separating macro-budget decisions from asset-level prioritization and integrating linear programming projection within a hierarchical Soft Actor-Critic framework, the method efficiently addresses exponential growth in the action space and ensures rigorous budget compliance. A case study evaluating sewer networks of varying sizes (10, 15, and 20 sewersheds) illustrates the effectiveness of the proposed approach. Compared to conventional Deep Q-Learning and enhanced genetic algorithms, our methodology converges more rapidly, scales effectively, and consistently delivers near-optimal solutions even as network size grows.",
      "publication_date": "2025-07-25T17:42:34+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.AI"
      ],
      "arxiv_id": "2507.19458v1"
    },
    {
      "title": "Learning Optimization Proxies for Large-Scale Security-Constrained   Economic Dispatch",
      "authors": [
        "Wenbo Chen",
        "Seonho Park",
        "Mathieu Tanneau",
        "Pascal Van Hentenryck"
      ],
      "abstract": "The Security-Constrained Economic Dispatch (SCED) is a fundamental optimization model for Transmission System Operators (TSO) to clear real-time energy markets while ensuring reliable operations of power grids. In a context of growing operational uncertainty, due to increased penetration of renewable generators and distributed energy resources, operators must continuously monitor risk in real-time, i.e., they must quickly assess the system's behavior under various changes in load and renewable production. Unfortunately, systematically solving an optimization problem for each such scenario is not practical given the tight constraints of real-time operations. To overcome this limitation, this paper proposes to learn an optimization proxy for SCED, i.e., a Machine Learning (ML) model that can predict an optimal solution for SCED in milliseconds. Motivated by a principled analysis of the market-clearing optimizations of MISO, the paper proposes a novel ML pipeline that addresses the main challenges of learning SCED solutions, i.e., the variability in load, renewable output and production costs, as well as the combinatorial structure of commitment decisions. A novel Classification-Then-Regression architecture is also proposed, to further capture the behavior of SCED solutions. Numerical experiments are reported on the French transmission system, and demonstrate the approach's ability to produce, within a time frame that is compatible with real-time operations, accurate optimization proxies that produce relative errors below $0.6\\%$.",
      "publication_date": "2021-12-27T00:44:06+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "cs.LG"
      ],
      "arxiv_id": "2112.13469v1"
    },
    {
      "title": "Portfolio choice, portfolio liquidation, and portfolio transition under   drift uncertainty",
      "authors": [
        "Alexis Bismuth",
        "Olivier Guant",
        "Jiang Pu"
      ],
      "abstract": "This paper presents several models addressing optimal portfolio choice, optimal portfolio liquidation, and optimal portfolio transition issues, in which the expected returns of risky assets are unknown. Our approach is based on a coupling between Bayesian learning and dynamic programming techniques that leads to partial differential equations. It enables to recover the well-known results of Karatzas and Zhao in a framework \\`a la Merton, but also to deal with cases where martingale methods are no longer available. In particular, we address optimal portfolio choice, portfolio liquidation, and portfolio transition problems in a framework \\`a la Almgren-Chriss, and we build therefore a model in which the agent takes into account in his decision process both the liquidity of assets and the uncertainty with respect to their expected return.",
      "publication_date": "2016-11-23T15:36:24+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "q-fin.PM"
      ],
      "arxiv_id": "1611.07843v7"
    },
    {
      "title": "Security of Distributed Parameter Cyber-Physical Systems: Cyber-Attack   Detection in Linear Parabolic PDEs",
      "authors": [
        "Tanushree Roy",
        "Satadru Dey"
      ],
      "abstract": "Security of Distributed Parameter Cyber-Physical Systems (DPCPSs) is of critical importance in the face of cyber-attack threats. Although security aspects of Cyber-Physical Systems (CPSs) modelled by Ordinary differential Equations (ODEs) have been extensively explored during the past decade, security of DPCPSs has not received its due attention despite its safety-critical nature. In this work, we explore the security aspects of DPCPSs from a system theoretic viewpoint. Specifically, we focus on DPCPSs modelled by linear parabolic Partial Differential Equations (PDEs) subject to cyber-attacks in actuation channel. First, we explore the detectability of such attacks and derive conditions for stealthy attacks. Next, we develop a design framework for cyber-attack detection algorithms based on output injection observers. Such attack detection algorithms explicitly consider stability, robustness and attack sensitivity in their design. Finally, theoretical analysis and simulation studies are performed to illustrate the effectiveness of the proposed approach.",
      "publication_date": "2021-07-29T16:29:43+00:00",
      "doi": "10.1109/TCST.2023.3263395",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "eess.SY"
      ],
      "arxiv_id": "2107.14159v2"
    },
    {
      "title": "Pareto Optimization in Categories",
      "authors": [
        "Matilde Marcolli"
      ],
      "abstract": "We propose a model of Pareto optimization (multi-objective programming) in the context of a categorical theory of resources. We describe how to adapt multi-objective swarm intelligence algorithms to this categorical formulation.",
      "publication_date": "2022-04-25T19:13:08+00:00",
      "doi": "",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.CT"
      ],
      "arxiv_id": "2204.11931v1"
    },
    {
      "title": "Effective Budget of Uncertainty for Classes of Robust Optimization",
      "authors": [
        "Milad Dehghani Filabadi",
        "Houra Mahmoudzadeh"
      ],
      "abstract": "Robust optimization (RO) tackles data uncertainty by optimizing for the worst-case scenario of an uncertain parameter and, in its basic form, is sometimes criticized for producing overly-conservative solutions. To reduce the level of conservatism in RO, one can use the well-known budget-of-uncertainty approach which limits the amount of uncertainty to be considered in the model. In this paper, we study a class of problems with resource uncertainty and propose a robust optimization methodology that produces solutions that are even less conservative than the conventional budget-of-uncertainty approach. We propose a new tractable two-stage robust optimization approach that identifies the \"ineffective\" parts of the uncertainty set and optimizes for the \"effective\" worst-case scenario only. In the first stage, we identify the effective range of the uncertain parameter, and in the second stage, we provide a formulation that eliminates the unnecessary protection for the ineffective parts, and hence, produces less conservative solutions and provides intuitive insights on the trade-off between robustness and solution conservatism. We demonstrate the applicability of the proposed approach using a power dispatch optimization problem with wind uncertainty. We also provide examples of other application areas that would benefit from the proposed approach.",
      "publication_date": "2019-07-05T16:36:11+00:00",
      "doi": "10.1287/ijoo.2021.0069",
      "venue": "arXiv preprint",
      "citation_count": 0,
      "keywords": [
        "math.OC"
      ],
      "arxiv_id": "1907.02917v5"
    }
  ]
}